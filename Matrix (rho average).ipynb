{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xitMVJTU_gpG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import networkx as nx\n",
        "from scipy.spatial import KDTree\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZzNLz3sAjfg"
      },
      "outputs": [],
      "source": [
        "english = np.load('/content/drive/MyDrive/languages/english_newlit_cbow_3_dict.npy', allow_pickle=True)[()]\n",
        "french = np.load('/content/drive/MyDrive/languages/french_newlit_cbow_3_dict.npy', allow_pickle=True)[()]\n",
        "german = np.load('/content/drive/MyDrive/languages/german_newlit_cbow_3_dict.npy', allow_pickle=True)[()]\n",
        "russian = np.load('/content/drive/MyDrive/languages/russian_nofraglit_cbow_3_dict.npy', allow_pickle=True)[()]\n",
        "vietnamese = np.load('/content/drive/MyDrive/languages/vietnamese_oldlit_SVD_dict.npy', allow_pickle=True)[()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLoUIfFRAk9Z",
        "outputId": "e997f351-b968-45f5-aa56-d2c7284af8d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "english:  153058\n",
            "english:  510936\n",
            "english:  1425674\n",
            "english:  364473\n",
            "english:  53688\n"
          ]
        }
      ],
      "source": [
        "print(\"english: \", len(english))\n",
        "print(\"english: \", len(french))\n",
        "print(\"english: \", len(german))\n",
        "print(\"english: \", len(russian))\n",
        "print(\"english: \", len(vietnamese))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PczsXfGjAn1G",
        "outputId": "7366496f-9bef-4b74-a572-288ef4b8f898"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(500, 3)\n"
          ]
        }
      ],
      "source": [
        "random.seed(42)\n",
        "\n",
        "\n",
        "sample_size = int(500)\n",
        "sampled_items = random.sample(list(english.items()), sample_size)\n",
        "\n",
        "\n",
        "sampled_arrays = [value for key, value in sampled_items]\n",
        "\n",
        "\n",
        "english_sample = np.vstack(sampled_arrays)\n",
        "\n",
        "\n",
        "print(english_sample.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aDEK9ChApce"
      },
      "outputs": [],
      "source": [
        "def rips_vietoris_graph(points, r):\n",
        "    tree = KDTree(points)\n",
        "    edges = list(tree.query_pairs(r))\n",
        "    G = nx.Graph()\n",
        "    G.add_nodes_from(range(len(points)))\n",
        "    G.add_edges_from(edges)\n",
        "    return G"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NkhlUkgArR8"
      },
      "outputs": [],
      "source": [
        "G_english = rips_vietoris_graph(english_sample, 0.526)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TV6CG5PFBhFJ",
        "outputId": "ffa74393-2685-4c16-8f1f-961cb929be74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(500, 3)\n"
          ]
        }
      ],
      "source": [
        "random.seed(42)\n",
        "\n",
        "\n",
        "sample_size = int(500)\n",
        "sampled_items = random.sample(list(french.items()), sample_size)\n",
        "\n",
        "\n",
        "sampled_arrays = [value for key, value in sampled_items]\n",
        "\n",
        "\n",
        "french_sample = np.vstack(sampled_arrays)\n",
        "\n",
        "\n",
        "print(french_sample.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zARXnJoBtR5"
      },
      "outputs": [],
      "source": [
        "G_french = rips_vietoris_graph(french_sample, 0.526)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwYfbs3eJScV",
        "outputId": "ebf85d3e-5e78-4bef-be10-d0e9442cc2da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(500, 3)\n"
          ]
        }
      ],
      "source": [
        "random.seed(42)\n",
        "\n",
        "\n",
        "sample_size = int(500)\n",
        "sampled_items = random.sample(list(german.items()), sample_size)\n",
        "\n",
        "\n",
        "sampled_arrays = [value for key, value in sampled_items]\n",
        "\n",
        "german_sample = np.vstack(sampled_arrays)\n",
        "\n",
        "\n",
        "print(german_sample.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O50i2mf9JVPp"
      },
      "outputs": [],
      "source": [
        "G_german = rips_vietoris_graph(german_sample, 0.526)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DytDPhjJZcq",
        "outputId": "edf4be6c-ec28-45a9-d72e-ab7191be347a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(500, 3)\n"
          ]
        }
      ],
      "source": [
        "random.seed(42)\n",
        "\n",
        "\n",
        "sample_size = int(500)\n",
        "sampled_items = random.sample(list(russian.items()), sample_size)\n",
        "\n",
        "\n",
        "sampled_arrays = [value for key, value in sampled_items]\n",
        "\n",
        "\n",
        "russian_sample = np.vstack(sampled_arrays)\n",
        "\n",
        "\n",
        "print(russian_sample.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NISxuljUJbyt"
      },
      "outputs": [],
      "source": [
        "G_russian = rips_vietoris_graph(russian_sample, 0.526)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lszo1k4eAThn",
        "outputId": "840fa921-19a6-41f3-c595-c029c1cc0a83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "iter:1899, smaller than eps\n",
            "0.9 0.003985538147389889 0.0\n",
            "100 0.00011775994062190875 0.0\n",
            "iter:699, smaller than eps\n",
            "0.5 0.005888083484023809 0.002\n",
            "100 0.00010958898928947747 0.002\n",
            "iter:1199, smaller than eps\n",
            "0.2 0.009756674990057945 0.002\n",
            "100 0.00011081965931225568 0.0\n",
            "iter:1099, smaller than eps\n",
            "0.1 0.013679437339305878 0.004\n",
            "100 7.909545092843473e-05 0.004\n",
            "iter:999, smaller than eps\n",
            "0.05 0.018839208409190178 0.002\n",
            "100 6.21884100837633e-05 0.002\n",
            "iter:549, smaller than eps\n",
            "0.01 0.7001632452011108 0.002\n",
            "100 5.635307024931535e-05 0.0\n",
            "0.001 nan 0.002\n",
            "100 nan 0.002\n",
            "rho:0.9,gap:3.99e-03,acc:0.00000,time:35.8,gap2:1.18e-04,acc2:0.00000,time2:37.5\n",
            "rho:0.5,gap:5.89e-03,acc:0.20000,time:13.1,gap2:1.10e-04,acc2:0.20000,time2:14.7\n",
            "rho:0.2,gap:9.76e-03,acc:0.20000,time:22.8,gap2:1.11e-04,acc2:0.00000,time2:24.5\n",
            "rho:0.1,gap:1.37e-02,acc:0.40000,time:19.6,gap2:7.91e-05,acc2:0.40000,time2:21.9\n",
            "rho:0.05,gap:1.88e-02,acc:0.20000,time:18.9,gap2:6.22e-05,acc2:0.20000,time2:20.6\n",
            "rho:0.01,gap:7.00e-01,acc:0.20000,time:123.5,gap2:5.64e-05,acc2:0.00000,time2:125.1\n",
            "rho:0.001,gap:nan,acc:0.20000,time:43.8,gap2:nan,acc2:0.20000,time2:46.8\n",
            "----------\n",
            "<class 'networkx.classes.graph.Graph'>    <class 'networkx.classes.graph.Graph'>\n",
            "---\n",
            "<class 'numpy.ndarray'>    <class 'numpy.ndarray'>\n",
            "----------\n",
            "----------\n",
            "[([-0.26441091299057007, -0.2990509569644928, -0.3266068696975708, -0.3436487913131714, -0.34890782833099365, -0.35124942660331726, -0.3525005578994751, -0.3532329797744751, -0.3536801338195801, -0.3539537191390991, -0.35411667823791504, -0.35421350598335266, -0.35427334904670715, -0.3543124794960022, -0.3543402850627899, -0.35436251759529114, -0.35438260436058044, -0.3544018566608429, -0.3544204831123352, -0.35443830490112305, -0.35445523262023926, -0.354471355676651, -0.3544868528842926, -0.35450178384780884, -0.35451582074165344, -0.35452863574028015, -0.35453999042510986, -0.3545498251914978, -0.3545582592487335, -0.3545655906200409, -0.35457226634025574, -0.35457882285118103, -0.3545853793621063, -0.3545917868614197, -0.35459762811660767, -0.35460248589515686, -0.3546063005924225, -0.35460925102233887], [-0.32530447840690613, -0.3223889172077179]), ([-0.2990912199020386, -0.34641873836517334, -0.35870805382728577, -0.3619019091129303, -0.3630138039588928, -0.3633968234062195, -0.36357006430625916, -0.36368328332901, -0.3637707531452179, -0.36383578181266785, -0.3638756573200226, -0.36389341950416565, -0.36389780044555664, -0.3639006018638611], [-0.3211265206336975, -0.31970736384391785]), ([-0.36822381615638733, -0.3763410151004791, -0.3771596848964691, -0.3774068355560303, -0.3776197135448456, -0.37781772017478943, -0.37796273827552795, -0.3780783712863922, -0.37820208072662354, -0.37833431363105774, -0.37845292687416077, -0.3785265386104584, -0.37856587767601013, -0.37860143184661865, -0.37863844633102417, -0.37867316603660583, -0.37870559096336365, -0.37873584032058716, -0.378762811422348, -0.37878721952438354, -0.37880831956863403, -0.37882328033447266, -0.3788304030895233, -0.3788298964500427], [-0.3157466948032379, -0.31547248363494873]), ([-0.3824447691440582, -0.383384644985199, -0.3837580382823944, -0.3839578926563263, -0.3841198980808258, -0.3842610716819763, -0.38441482186317444, -0.3845347762107849, -0.3846115469932556, -0.38467803597450256, -0.38472917675971985, -0.3847481608390808, -0.3847272992134094, -0.38468602299690247, -0.38464784622192383, -0.3846152424812317, -0.3845859169960022, -0.3845665454864502, -0.38454508781433105, -0.38455280661582947, -0.3845251798629761, -0.3845268189907074], [-0.3123573064804077, -0.31242236495018005]), ([-0.3886019289493561, -0.38893935084342957, -0.388771116733551, -0.3886326253414154, -0.38862526416778564, -0.38864248991012573, -0.38862931728363037, -0.3885524272918701, -0.38848140835762024, -0.38849157094955444, -0.3885742127895355, -0.3886183202266693, -0.388711541891098, -0.3887765407562256, -0.38880404829978943, -0.38882797956466675, -0.38884902000427246, -0.38886329531669617, -0.3888682425022125, -0.38886773586273193], [-0.30560776591300964, -0.30606845021247864]), ([-0.06527181714773178, -0.06666015833616257, -0.066370889544487, -0.0663611963391304, -0.06636441498994827, -0.06636776775121689, -0.06637800484895706, -0.06638867408037186, -0.06638506799936295, -0.0663931742310524, -0.06639347225427628], [-0.2194129079580307, -0.22029581665992737]), ([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], [nan, nan])]\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "import pickle\n",
        "from BAPG import *\n",
        "import torch\n",
        "import time\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
        "def defaul():\n",
        "    return defaultdict(list)\n",
        "\n",
        "\n",
        "def BAPG_torch(A, B, a=None, b=None, X=None, epoch=200, eps=1e-5, rho=1e-1):\n",
        "    if a is None:\n",
        "        #a = torch.ones([A.shape[0], 1], dtype=A.dtype).cuda()/A.shape[0]\n",
        "        a = torch.ones([A.shape[0], 1], dtype=A.dtype)/A.shape[0]\n",
        "    if b is None:\n",
        "        #b = torch.ones([B.shape[0], 1], dtype=A.dtype).cuda()/B.shape[0]\n",
        "        b = torch.ones([B.shape[0], 1], dtype=A.dtype)/B.shape[0]\n",
        "    if X is None:\n",
        "        X = a@b.T\n",
        "    obj_list, obj1_list, obj2_list, gap_list = [], [], [], []\n",
        "    for ii in range(epoch):\n",
        "        X = X + 1e-10\n",
        "        X = torch.exp(A@X@B/rho)*X\n",
        "        pi = X * (a / (X @ torch.ones_like(b)))\n",
        "        X = torch.exp(A@pi@B/rho)*pi\n",
        "        X = X * (b.T / (X.T @ torch.ones_like(a)).T)\n",
        "        if (ii+1) % 50 == 0:\n",
        "            objective = -torch.trace(A @ X @ B @ X.T).item()\n",
        "            X2 = (X+pi)/2\n",
        "            gap = (X2.sum(0)-b.squeeze(-1)).norm() + (X2.sum(1)-a.squeeze(-1)).norm()\n",
        "            gap_list.append(gap.item())\n",
        "            if len(obj_list) > 0 and np.abs((objective-obj_list[-1])/obj_list[-1]) < eps:\n",
        "                print('iter:{}, smaller than eps'.format(ii))\n",
        "                obj_list.append(objective)\n",
        "                break\n",
        "            obj_list.append(objective)\n",
        "    return X2, obj_list, gap_list\n",
        "\n",
        "\n",
        "def BAPG_numpy(A, B, a=None, b=None, X=None, epoch=200, eps=1e-5, rho=1e-1):\n",
        "    if a is None:\n",
        "        a = np.ones([A.shape[0], 1], dtype=A.dtype)/A.shape[0]\n",
        "    if b is None:\n",
        "        b = np.ones([B.shape[0], 1], dtype=A.dtype)/B.shape[0]\n",
        "    if X is None:\n",
        "        X = a@b.T\n",
        "    obj_list, gap_list = [], []\n",
        "    for ii in range(epoch):\n",
        "        X = X+1e-10\n",
        "        X = np.exp(A@X@B/rho)*X\n",
        "        pi = X * (a / (X @ np.ones_like(b)))\n",
        "        X = np.exp(A@pi@B/rho)*pi\n",
        "        X = X * (b.T / (X.T @ np.ones_like(a)).T)\n",
        "        if (ii+1) % 50 == 0:\n",
        "            X2 = (X+pi)/2\n",
        "            gap = np.linalg.norm((X2.sum(0)-b.squeeze(-1))) + np.linalg.norm(X2.sum(1)-a.squeeze(-1))\n",
        "            gap_list.append(gap.item())\n",
        "            objective = -np.trace(A @ X @ B @ X.T)\n",
        "            if len(obj_list) > 0 and np.abs((objective-obj_list[-1])/obj_list[-1]) < eps:\n",
        "                print('iter:{}, smaller than eps'.format(ii))\n",
        "                break\n",
        "            obj_list.append(objective)\n",
        "    return X2, obj_list, gap_list\n",
        "seed = 123\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "database = \"synthetic\"\n",
        "rho_list = [0.9, 0.5, 0.2, 0.1, 0.05, 0.01, 0.001]\n",
        "\n",
        "# parser = argparse.ArgumentParser()\n",
        "# parser.add_argument('--dataset', type=str, default='proteins', help='proteins / reddit / enzymes / synthetic')\n",
        "# parser.add_argument('--noise_level', type=float, default=0.)\n",
        "# parser.add_argument('--use_gpu', type=bool, default=False)\n",
        "# parser.add_argument('--loss_fun', type=str, default='square_loss', help='square_loss/kl_loss')\n",
        "# parser.add_argument('--rho', type=float, default=[0.5, 0.2, 0.1, 0.05, 0.01], nargs='+')\n",
        "\n",
        "# args = parser.parse_args()\n",
        "# rho_list = [0.5, 0.2, 0.1, 0.05, 0.01]\n",
        "# database = \"synthetic\"\n",
        "# noise_level = args.noise_level\n",
        "\n",
        "# if database == 'proteins':\n",
        "#     print('------------------Node Matching on PROTIENS---------------')\n",
        "#     with open('data/PROTEINS/matching.pk', 'rb') as f:\n",
        "#         graphs, _ = pickle.load(f)\n",
        "\n",
        "# if database == 'reddit':\n",
        "#     print('------------------Node Matching on REDDIT---------------')\n",
        "#     with open('data/REDDIT-BINARY/matching.pk', 'rb') as f:\n",
        "#         graphs = pickle.load(f)[:500]\n",
        "\n",
        "# if database == 'enzymes':\n",
        "#     print('------------------Node Matching on ENZYMES---------------')\n",
        "#     with open('data/ENZYMES/matching.pk', 'rb') as f:\n",
        "#         graphs = pickle.load(f)\n",
        "\n",
        "\n",
        "#ppppppppppppppppp\n",
        "\n",
        "# if database == 'synthetic':\n",
        "#     graphs, noise_graphs = [], []\n",
        "#     print('------------------Node Matching on Synthetic Database---------------')\n",
        "#     with open('graph1.pk', 'rb') as f:\n",
        "#         graph_pairs = pickle.load(f)\n",
        "#         print(graph_pairs)\n",
        "#         for num_node in [100]:\n",
        "#             for noise_level in [0.1]:\n",
        "#                 for G, G_noise in graph_pairs[(num_node, noise_level)]:\n",
        "#                     graphs.append(G)\n",
        "#                     noise_graphs.append(G_noise)\n",
        "\n",
        "#ppppppppppppppppp\n",
        "\n",
        "# if database != 'synthetic':\n",
        "#     if noise_level > 0:\n",
        "#         noise_graphs = []\n",
        "#         for G_src in graphs:\n",
        "#             G_dst = add_noisy_edges(G_src, noise_level)\n",
        "#             G_dst = add_noisy_nodes(G_dst, noise_level)\n",
        "#             noise_graphs.append(G_dst)\n",
        "#     else:\n",
        "#         noise_graphs = graphs\n",
        "\n",
        "#################\n",
        "\n",
        "\n",
        "# graphs = [ellipse_graph]\n",
        "# noise_graphs = [rotated_ellipse_graph]\n",
        "\n",
        "graphs = [G_english]\n",
        "\n",
        "noise_graphs = [G_french]\n",
        "\n",
        "noise_level = 0.\n",
        "#################\n",
        "\n",
        "\n",
        "gap_rho = defaultdict(list)\n",
        "acc_rho = defaultdict(list)\n",
        "time_rho = defaultdict(list)\n",
        "gap2_rho = defaultdict(list)\n",
        "acc2_rho = defaultdict(list)\n",
        "time2_rho = defaultdict(list)\n",
        "obj_lists = []\n",
        "for j in range(len(graphs)):\n",
        "    print(j)\n",
        "    G = graphs[j]\n",
        "    G_noise = noise_graphs[j]\n",
        "    G_adj = nx.to_numpy_array(G).astype(np.float32)\n",
        "    G_adj_noise = nx.to_numpy_array(G_noise).astype(np.float32)\n",
        "    #G_adj_gpu = torch.tensor(G_adj).cuda()\n",
        "    G_adj_gpu = torch.tensor(G_adj)\n",
        "    #G_adj_noise_gpu = torch.tensor(G_adj_noise).cuda()\n",
        "    G_adj_noise_gpu = torch.tensor(G_adj_noise)\n",
        "    m, n = G_adj.shape[0], G_adj_noise.shape[0]\n",
        "    for rho in rho_list:  #0.5,0.2,0.1,0.05,\n",
        "        epoch = 2000 if rho < 0.2 else 4000\n",
        "        start = time.time()\n",
        "        # coup_bap, obj_list, gap_list = BAPG_numpy(\n",
        "        #     A=G_adj, B=G_adj_noise, epoch=2000, rho=rho, eps=1e-5, scaling=1.01, max_rho=0.5)\n",
        "        if True:\n",
        "            coup_bap, obj_list1, gap_list = BAPG_torch(\n",
        "                A=G_adj_gpu, B=G_adj_noise_gpu, epoch=epoch, rho=rho, eps=1e-5)\n",
        "            end = time.time()\n",
        "            acc = node_correctness(coup_bap.cpu().numpy(), np.eye(m))\n",
        "            print(rho, gap_list[-1], acc)\n",
        "            acc_rho[rho].append(acc)\n",
        "            time_rho[rho].append(end-start)\n",
        "            gap_rho[rho].append(gap_list[-1])\n",
        "            coup_bap, obj_list2, gap_list = BAPG_torch(\n",
        "                A=G_adj_gpu, B=G_adj_noise_gpu, X=coup_bap, epoch=100, rho=100, eps=1e-5)\n",
        "            end = time.time()\n",
        "            obj_lists.append((obj_list1, obj_list2))\n",
        "            acc = node_correctness(coup_bap.cpu().numpy(), np.eye(m))\n",
        "            print('100', gap_list[-1], acc)\n",
        "        else:\n",
        "            coup_bap, obj_list1, gap_list = BAPG_numpy(\n",
        "                A=G_adj, B=G_adj_noise, epoch=2000, rho=rho, eps=1e-5)\n",
        "            end = time.time()\n",
        "            print(\"fffff\")\n",
        "            print(obj_list1)\n",
        "            print(\"fffff\")\n",
        "            acc = node_correctness(coup_bap, np.eye(m))\n",
        "            print(rho, gap_list[-1], acc)\n",
        "            acc_rho[rho].append(acc)\n",
        "            time_rho[rho].append(end-start)\n",
        "            gap_rho[rho].append(gap_list[-1])\n",
        "            coup_bap, obj_list2, gap_list = BAPG_numpy(\n",
        "                A=G_adj, B=G_adj_noise, X=coup_bap, epoch=100, rho=100, eps=1e-5)\n",
        "            end = time.time()\n",
        "            obj_lists.append((obj_list1, obj_list2))\n",
        "            acc = node_correctness(coup_bap, np.eye(m))\n",
        "            print('100', gap_list[-1], acc)\n",
        "\n",
        "        acc2_rho[rho].append(acc)\n",
        "        time2_rho[rho].append(end-start)\n",
        "        gap2_rho[rho].append(gap_list[-1])\n",
        "\n",
        "\n",
        "for rho in rho_list:\n",
        "    print('rho:{},gap:{:.2e},acc:{:.5f},time:{:.1f},gap2:{:.2e},acc2:{:.5f},time2:{:.1f}'.format(\n",
        "        rho, np.mean(gap_rho[rho]), np.mean(acc_rho[rho])*100, np.sum(time_rho[rho]),\n",
        "        np.mean(gap2_rho[rho]), np.mean(acc2_rho[rho])*100, np.sum(time2_rho[rho])))\n",
        "\n",
        "    with open('result.txt', 'a+') as f:\n",
        "        f.write('Data:{},Noise:{},rho:{},gap:{:.2e},acc:{:.5f},time:{:.1f},gap2:{:.2e},acc2:{:.5f},time2:{:.1f}\\n'.format(\n",
        "            database, noise_level, rho, np.mean(gap_rho[rho]), np.mean(acc_rho[rho])*100, np.sum(time_rho[rho]),\n",
        "            np.mean(gap2_rho[rho]), np.mean(acc2_rho[rho])*100, np.sum(time2_rho[rho])))\n",
        "print('-'*10)\n",
        "print(type(G), type(G_noise), sep=\"    \")\n",
        "print('-'*3)\n",
        "print(type(G_adj), type(G_adj_noise), sep=\"    \")\n",
        "print('-'*10)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# nx.draw_networkx(G, with_labels=True, node_size=10, pos=nx.spring_layout(G), font_size=8, width=0.1)\n",
        "# plt.savefig(\"G.png\")\n",
        "# nx.draw_networkx(G_noise, with_labels=True, node_size=10, font_size=8, width=0.1)\n",
        "# plt.savefig(\"G_noise.png\")\n",
        "\n",
        "\n",
        "\n",
        "print('-'*10)\n",
        "print(obj_lists)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZdh5r_vKNpW",
        "outputId": "a24ebd13-280e-4d04-90ea-ba6f3ab08991"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "iter:1199, smaller than eps\n",
            "0.9 0.005885802675038576 0.004\n",
            "100 0.00010354116966482252 0.004\n",
            "iter:649, smaller than eps\n",
            "0.5 0.00895586609840393 0.002\n",
            "100 9.847397450357676e-05 0.002\n",
            "iter:949, smaller than eps\n",
            "0.2 0.014505339786410332 0.0\n",
            "100 0.00011557472316781059 0.0\n",
            "iter:1099, smaller than eps\n",
            "0.1 0.01860576495528221 0.0\n",
            "100 0.00010548965656198561 0.0\n",
            "iter:1349, smaller than eps\n",
            "0.05 0.023914603516459465 0.004\n",
            "100 7.57519737817347e-05 0.004\n",
            "iter:399, smaller than eps\n",
            "0.01 0.7293136119842529 0.002\n",
            "100 5.023238554713316e-05 0.004\n",
            "0.001 nan 0.002\n",
            "100 nan 0.002\n",
            "rho:0.9,gap:5.89e-03,acc:0.40000,time:22.0,gap2:1.04e-04,acc2:0.40000,time2:23.7\n",
            "rho:0.5,gap:8.96e-03,acc:0.20000,time:12.4,gap2:9.85e-05,acc2:0.20000,time2:14.0\n",
            "rho:0.2,gap:1.45e-02,acc:0.00000,time:18.5,gap2:1.16e-04,acc2:0.00000,time2:20.6\n",
            "rho:0.1,gap:1.86e-02,acc:0.00000,time:20.1,gap2:1.05e-04,acc2:0.00000,time2:21.8\n",
            "rho:0.05,gap:2.39e-02,acc:0.40000,time:25.6,gap2:7.58e-05,acc2:0.40000,time2:27.3\n",
            "rho:0.01,gap:7.29e-01,acc:0.20000,time:85.8,gap2:5.02e-05,acc2:0.40000,time2:87.8\n",
            "rho:0.001,gap:nan,acc:0.20000,time:44.4,gap2:nan,acc2:0.20000,time2:46.4\n",
            "----------\n",
            "<class 'networkx.classes.graph.Graph'>    <class 'networkx.classes.graph.Graph'>\n",
            "---\n",
            "<class 'numpy.ndarray'>    <class 'numpy.ndarray'>\n",
            "----------\n",
            "----------\n",
            "[([-0.28539004921913147, -0.31469306349754333, -0.34780067205429077, -0.3708144426345825, -0.37754857540130615, -0.3802696764469147, -0.3816450536251068, -0.3824683129787445, -0.3830026090145111, -0.38336360454559326, -0.3836132287979126, -0.38378822803497314, -0.3839114308357239, -0.3839956820011139, -0.38404911756515503, -0.38407593965530396, -0.38408008217811584, -0.38406887650489807, -0.3840499520301819, -0.38402968645095825, -0.38401293754577637, -0.38400182127952576, -0.38399559259414673, -0.38399192690849304], [-0.33111467957496643, -0.33030614256858826]), ([-0.3209850788116455, -0.3831702172756195, -0.39776986837387085, -0.40152907371520996, -0.4031168222427368, -0.4040110409259796, -0.4045190215110779, -0.40478548407554626, -0.40492716431617737, -0.4050164222717285, -0.4050762355327606, -0.4051028788089752, -0.4051022231578827], [-0.32672086358070374, -0.32626137137413025]), ([-0.4205351769924164, -0.4314585030078888, -0.43287214636802673, -0.4331439435482025, -0.43313920497894287, -0.4330725073814392, -0.43299031257629395, -0.43294838070869446, -0.4329414665699005, -0.4329897165298462, -0.433079332113266, -0.4331783056259155, -0.43323761224746704, -0.4332238733768463, -0.43313664197921753, -0.4330265522003174, -0.4329545199871063, -0.4329262673854828, -0.432923287153244], [-0.3217802047729492, -0.3215593099594116]), ([-0.4425092935562134, -0.4439942240715027, -0.44417017698287964, -0.4442858099937439, -0.44438424706459045, -0.44447553157806396, -0.44452711939811707, -0.44457879662513733, -0.44462859630584717, -0.44468846917152405, -0.4447847604751587, -0.44482776522636414, -0.44484391808509827, -0.4448680579662323, -0.44488853216171265, -0.44490379095077515, -0.44491007924079895, -0.44490334391593933, -0.4449097812175751, -0.4449320137500763, -0.4449410140514374, -0.444940447807312], [-0.3187214136123657, -0.3188011944293976]), ([-0.45033255219459534, -0.4505597949028015, -0.45059239864349365, -0.45061981678009033, -0.4505974352359772, -0.45066672563552856, -0.4509056806564331, -0.451179176568985, -0.4511149227619171, -0.4510582685470581, -0.45108288526535034, -0.4511849582195282, -0.451204389333725, -0.4511757791042328, -0.4511372447013855, -0.45110175013542175, -0.45109519362449646, -0.4511255919933319, -0.4511811435222626, -0.45110929012298584, -0.4510631859302521, -0.4510382115840912, -0.45100268721580505, -0.45094960927963257, -0.45097115635871887, -0.4509471654891968, -0.4509478807449341], [-0.31502604484558105, -0.31547486782073975]), ([-0.07825155556201935, -0.07849907875061035, -0.07864565402269363, -0.07876184582710266, -0.07876858115196228, -0.07874785363674164, -0.07872498035430908, -0.07872553169727325], [-0.22585511207580566, -0.22709830105304718]), ([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], [nan, nan])]\n"
          ]
        }
      ],
      "source": [
        "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
        "def defaul():\n",
        "    return defaultdict(list)\n",
        "\n",
        "\n",
        "def BAPG_torch(A, B, a=None, b=None, X=None, epoch=200, eps=1e-5, rho=1e-1):\n",
        "    if a is None:\n",
        "        #a = torch.ones([A.shape[0], 1], dtype=A.dtype).cuda()/A.shape[0]\n",
        "        a = torch.ones([A.shape[0], 1], dtype=A.dtype)/A.shape[0]\n",
        "    if b is None:\n",
        "        #b = torch.ones([B.shape[0], 1], dtype=A.dtype).cuda()/B.shape[0]\n",
        "        b = torch.ones([B.shape[0], 1], dtype=A.dtype)/B.shape[0]\n",
        "    if X is None:\n",
        "        X = a@b.T\n",
        "    obj_list, obj1_list, obj2_list, gap_list = [], [], [], []\n",
        "    for ii in range(epoch):\n",
        "        X = X + 1e-10\n",
        "        X = torch.exp(A@X@B/rho)*X\n",
        "        pi = X * (a / (X @ torch.ones_like(b)))\n",
        "        X = torch.exp(A@pi@B/rho)*pi\n",
        "        X = X * (b.T / (X.T @ torch.ones_like(a)).T)\n",
        "        if (ii+1) % 50 == 0:\n",
        "            objective = -torch.trace(A @ X @ B @ X.T).item()\n",
        "            X2 = (X+pi)/2\n",
        "            gap = (X2.sum(0)-b.squeeze(-1)).norm() + (X2.sum(1)-a.squeeze(-1)).norm()\n",
        "            gap_list.append(gap.item())\n",
        "            if len(obj_list) > 0 and np.abs((objective-obj_list[-1])/obj_list[-1]) < eps:\n",
        "                print('iter:{}, smaller than eps'.format(ii))\n",
        "                obj_list.append(objective)\n",
        "                break\n",
        "            obj_list.append(objective)\n",
        "    return X2, obj_list, gap_list\n",
        "\n",
        "\n",
        "def BAPG_numpy(A, B, a=None, b=None, X=None, epoch=200, eps=1e-5, rho=1e-1):\n",
        "    if a is None:\n",
        "        a = np.ones([A.shape[0], 1], dtype=A.dtype)/A.shape[0]\n",
        "    if b is None:\n",
        "        b = np.ones([B.shape[0], 1], dtype=A.dtype)/B.shape[0]\n",
        "    if X is None:\n",
        "        X = a@b.T\n",
        "    obj_list, gap_list = [], []\n",
        "    for ii in range(epoch):\n",
        "        X = X+1e-10\n",
        "        X = np.exp(A@X@B/rho)*X\n",
        "        pi = X * (a / (X @ np.ones_like(b)))\n",
        "        X = np.exp(A@pi@B/rho)*pi\n",
        "        X = X * (b.T / (X.T @ np.ones_like(a)).T)\n",
        "        if (ii+1) % 50 == 0:\n",
        "            X2 = (X+pi)/2\n",
        "            gap = np.linalg.norm((X2.sum(0)-b.squeeze(-1))) + np.linalg.norm(X2.sum(1)-a.squeeze(-1))\n",
        "            gap_list.append(gap.item())\n",
        "            objective = -np.trace(A @ X @ B @ X.T)\n",
        "            if len(obj_list) > 0 and np.abs((objective-obj_list[-1])/obj_list[-1]) < eps:\n",
        "                print('iter:{}, smaller than eps'.format(ii))\n",
        "                break\n",
        "            obj_list.append(objective)\n",
        "    return X2, obj_list, gap_list\n",
        "seed = 123\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "database = \"synthetic\"\n",
        "rho_list = [0.9, 0.5, 0.2, 0.1, 0.05, 0.01, 0.001]\n",
        "\n",
        "# parser = argparse.ArgumentParser()\n",
        "# parser.add_argument('--dataset', type=str, default='proteins', help='proteins / reddit / enzymes / synthetic')\n",
        "# parser.add_argument('--noise_level', type=float, default=0.)\n",
        "# parser.add_argument('--use_gpu', type=bool, default=False)\n",
        "# parser.add_argument('--loss_fun', type=str, default='square_loss', help='square_loss/kl_loss')\n",
        "# parser.add_argument('--rho', type=float, default=[0.5, 0.2, 0.1, 0.05, 0.01], nargs='+')\n",
        "\n",
        "# args = parser.parse_args()\n",
        "# rho_list = [0.5, 0.2, 0.1, 0.05, 0.01]\n",
        "# database = \"synthetic\"\n",
        "# noise_level = args.noise_level\n",
        "\n",
        "# if database == 'proteins':\n",
        "#     print('------------------Node Matching on PROTIENS---------------')\n",
        "#     with open('data/PROTEINS/matching.pk', 'rb') as f:\n",
        "#         graphs, _ = pickle.load(f)\n",
        "\n",
        "# if database == 'reddit':\n",
        "#     print('------------------Node Matching on REDDIT---------------')\n",
        "#     with open('data/REDDIT-BINARY/matching.pk', 'rb') as f:\n",
        "#         graphs = pickle.load(f)[:500]\n",
        "\n",
        "# if database == 'enzymes':\n",
        "#     print('------------------Node Matching on ENZYMES---------------')\n",
        "#     with open('data/ENZYMES/matching.pk', 'rb') as f:\n",
        "#         graphs = pickle.load(f)\n",
        "\n",
        "\n",
        "#ppppppppppppppppp\n",
        "\n",
        "# if database == 'synthetic':\n",
        "#     graphs, noise_graphs = [], []\n",
        "#     print('------------------Node Matching on Synthetic Database---------------')\n",
        "#     with open('graph1.pk', 'rb') as f:\n",
        "#         graph_pairs = pickle.load(f)\n",
        "#         print(graph_pairs)\n",
        "#         for num_node in [100]:\n",
        "#             for noise_level in [0.1]:\n",
        "#                 for G, G_noise in graph_pairs[(num_node, noise_level)]:\n",
        "#                     graphs.append(G)\n",
        "#                     noise_graphs.append(G_noise)\n",
        "\n",
        "#ppppppppppppppppp\n",
        "\n",
        "# if database != 'synthetic':\n",
        "#     if noise_level > 0:\n",
        "#         noise_graphs = []\n",
        "#         for G_src in graphs:\n",
        "#             G_dst = add_noisy_edges(G_src, noise_level)\n",
        "#             G_dst = add_noisy_nodes(G_dst, noise_level)\n",
        "#             noise_graphs.append(G_dst)\n",
        "#     else:\n",
        "#         noise_graphs = graphs\n",
        "\n",
        "#################\n",
        "\n",
        "\n",
        "# graphs = [ellipse_graph]\n",
        "# noise_graphs = [rotated_ellipse_graph]\n",
        "\n",
        "graphs = [G_english]\n",
        "\n",
        "noise_graphs = [G_german]\n",
        "\n",
        "noise_level = 0.\n",
        "#################\n",
        "\n",
        "\n",
        "gap_rho = defaultdict(list)\n",
        "acc_rho = defaultdict(list)\n",
        "time_rho = defaultdict(list)\n",
        "gap2_rho = defaultdict(list)\n",
        "acc2_rho = defaultdict(list)\n",
        "time2_rho = defaultdict(list)\n",
        "obj_lists = []\n",
        "for j in range(len(graphs)):\n",
        "    print(j)\n",
        "    G = graphs[j]\n",
        "    G_noise = noise_graphs[j]\n",
        "    G_adj = nx.to_numpy_array(G).astype(np.float32)\n",
        "    G_adj_noise = nx.to_numpy_array(G_noise).astype(np.float32)\n",
        "    #G_adj_gpu = torch.tensor(G_adj).cuda()\n",
        "    G_adj_gpu = torch.tensor(G_adj)\n",
        "    #G_adj_noise_gpu = torch.tensor(G_adj_noise).cuda()\n",
        "    G_adj_noise_gpu = torch.tensor(G_adj_noise)\n",
        "    m, n = G_adj.shape[0], G_adj_noise.shape[0]\n",
        "    for rho in rho_list:  #0.5,0.2,0.1,0.05,\n",
        "        epoch = 2000 if rho < 0.2 else 4000\n",
        "        start = time.time()\n",
        "        # coup_bap, obj_list, gap_list = BAPG_numpy(\n",
        "        #     A=G_adj, B=G_adj_noise, epoch=2000, rho=rho, eps=1e-5, scaling=1.01, max_rho=0.5)\n",
        "        if True:\n",
        "            coup_bap, obj_list1, gap_list = BAPG_torch(\n",
        "                A=G_adj_gpu, B=G_adj_noise_gpu, epoch=epoch, rho=rho, eps=1e-5)\n",
        "            end = time.time()\n",
        "            acc = node_correctness(coup_bap.cpu().numpy(), np.eye(m))\n",
        "            print(rho, gap_list[-1], acc)\n",
        "            acc_rho[rho].append(acc)\n",
        "            time_rho[rho].append(end-start)\n",
        "            gap_rho[rho].append(gap_list[-1])\n",
        "            coup_bap, obj_list2, gap_list = BAPG_torch(\n",
        "                A=G_adj_gpu, B=G_adj_noise_gpu, X=coup_bap, epoch=100, rho=100, eps=1e-5)\n",
        "            end = time.time()\n",
        "            obj_lists.append((obj_list1, obj_list2))\n",
        "            acc = node_correctness(coup_bap.cpu().numpy(), np.eye(m))\n",
        "            print('100', gap_list[-1], acc)\n",
        "        else:\n",
        "            coup_bap, obj_list1, gap_list = BAPG_numpy(\n",
        "                A=G_adj, B=G_adj_noise, epoch=2000, rho=rho, eps=1e-5)\n",
        "            end = time.time()\n",
        "            print(\"fffff\")\n",
        "            print(obj_list1)\n",
        "            print(\"fffff\")\n",
        "            acc = node_correctness(coup_bap, np.eye(m))\n",
        "            print(rho, gap_list[-1], acc)\n",
        "            acc_rho[rho].append(acc)\n",
        "            time_rho[rho].append(end-start)\n",
        "            gap_rho[rho].append(gap_list[-1])\n",
        "            coup_bap, obj_list2, gap_list = BAPG_numpy(\n",
        "                A=G_adj, B=G_adj_noise, X=coup_bap, epoch=100, rho=100, eps=1e-5)\n",
        "            end = time.time()\n",
        "            obj_lists.append((obj_list1, obj_list2))\n",
        "            acc = node_correctness(coup_bap, np.eye(m))\n",
        "            print('100', gap_list[-1], acc)\n",
        "\n",
        "        acc2_rho[rho].append(acc)\n",
        "        time2_rho[rho].append(end-start)\n",
        "        gap2_rho[rho].append(gap_list[-1])\n",
        "\n",
        "\n",
        "for rho in rho_list:\n",
        "    print('rho:{},gap:{:.2e},acc:{:.5f},time:{:.1f},gap2:{:.2e},acc2:{:.5f},time2:{:.1f}'.format(\n",
        "        rho, np.mean(gap_rho[rho]), np.mean(acc_rho[rho])*100, np.sum(time_rho[rho]),\n",
        "        np.mean(gap2_rho[rho]), np.mean(acc2_rho[rho])*100, np.sum(time2_rho[rho])))\n",
        "\n",
        "    with open('result.txt', 'a+') as f:\n",
        "        f.write('Data:{},Noise:{},rho:{},gap:{:.2e},acc:{:.5f},time:{:.1f},gap2:{:.2e},acc2:{:.5f},time2:{:.1f}\\n'.format(\n",
        "            database, noise_level, rho, np.mean(gap_rho[rho]), np.mean(acc_rho[rho])*100, np.sum(time_rho[rho]),\n",
        "            np.mean(gap2_rho[rho]), np.mean(acc2_rho[rho])*100, np.sum(time2_rho[rho])))\n",
        "print('-'*10)\n",
        "print(type(G), type(G_noise), sep=\"    \")\n",
        "print('-'*3)\n",
        "print(type(G_adj), type(G_adj_noise), sep=\"    \")\n",
        "print('-'*10)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# nx.draw_networkx(G, with_labels=True, node_size=10, pos=nx.spring_layout(G), font_size=8, width=0.1)\n",
        "# plt.savefig(\"G.png\")\n",
        "# nx.draw_networkx(G_noise, with_labels=True, node_size=10, font_size=8, width=0.1)\n",
        "# plt.savefig(\"G_noise.png\")\n",
        "\n",
        "\n",
        "\n",
        "print('-'*10)\n",
        "print(obj_lists)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjC7Clm8KObT",
        "outputId": "c0fcd293-6776-47bc-ba3e-3a23ddf4ca9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "iter:1099, smaller than eps\n",
            "0.9 0.005083440337330103 0.002\n",
            "100 9.908372157951817e-05 0.002\n",
            "iter:1299, smaller than eps\n",
            "0.5 0.0067520891316235065 0.002\n",
            "100 0.00011351292778272182 0.002\n",
            "iter:499, smaller than eps\n",
            "0.2 0.01048203930258751 0.0\n",
            "100 0.00010298530105501413 0.0\n",
            "iter:549, smaller than eps\n",
            "0.1 0.013329808600246906 0.002\n",
            "100 9.29866946535185e-05 0.002\n",
            "iter:499, smaller than eps\n",
            "0.05 0.017576543614268303 0.0\n",
            "100 7.5626747275237e-05 0.0\n",
            "iter:499, smaller than eps\n",
            "0.01 0.6991822123527527 0.002\n",
            "100 5.4526251915376633e-05 0.004\n",
            "0.001 nan 0.002\n",
            "100 nan 0.002\n",
            "rho:0.9,gap:5.08e-03,acc:0.20000,time:21.2,gap2:9.91e-05,acc2:0.20000,time2:23.2\n",
            "rho:0.5,gap:6.75e-03,acc:0.20000,time:23.1,gap2:1.14e-04,acc2:0.20000,time2:25.8\n",
            "rho:0.2,gap:1.05e-02,acc:0.00000,time:9.0,gap2:1.03e-04,acc2:0.00000,time2:10.8\n",
            "rho:0.1,gap:1.33e-02,acc:0.20000,time:10.8,gap2:9.30e-05,acc2:0.20000,time2:12.4\n",
            "rho:0.05,gap:1.76e-02,acc:0.00000,time:9.9,gap2:7.56e-05,acc2:0.00000,time2:11.6\n",
            "rho:0.01,gap:6.99e-01,acc:0.20000,time:122.5,gap2:5.45e-05,acc2:0.40000,time2:124.3\n",
            "rho:0.001,gap:nan,acc:0.20000,time:45.4,gap2:nan,acc2:0.20000,time2:48.1\n",
            "----------\n",
            "<class 'networkx.classes.graph.Graph'>    <class 'networkx.classes.graph.Graph'>\n",
            "---\n",
            "<class 'numpy.ndarray'>    <class 'numpy.ndarray'>\n",
            "----------\n",
            "----------\n",
            "[([-0.27480030059814453, -0.3082358241081238, -0.3398476243019104, -0.3588469922542572, -0.3651231825351715, -0.368050754070282, -0.3697027862071991, -0.370731383562088, -0.3714055120944977, -0.3718675374984741, -0.3722008168697357, -0.37244877219200134, -0.37263399362564087, -0.37277328968048096, -0.3728789985179901, -0.37295836210250854, -0.3730159103870392, -0.37305542826652527, -0.37308067083358765, -0.3730951249599457, -0.3731011152267456, -0.37310028076171875], [-0.3280216157436371, -0.3271652162075043]), ([-0.31060919165611267, -0.361832857131958, -0.37671083211898804, -0.3801267147064209, -0.3814356327056885, -0.3820516765117645, -0.3823842704296112, -0.3826030194759369, -0.38276636600494385, -0.38289588689804077, -0.38300108909606934, -0.3830875754356384, -0.38315680623054504, -0.3832072615623474, -0.38323917984962463, -0.38325750827789307, -0.38326942920684814, -0.383279025554657, -0.3832874894142151, -0.3832951486110687, -0.3833020329475403, -0.38330820202827454, -0.38331368565559387, -0.3833182752132416, -0.383322149515152, -0.3833257555961609], [-0.3249620199203491, -0.32442498207092285]), ([-0.3873465955257416, -0.39668139815330505, -0.39759278297424316, -0.3979264795780182, -0.3981156051158905, -0.39820411801338196, -0.39822840690612793, -0.3982178568840027, -0.39820101857185364, -0.3982040286064148], [-0.3194653391838074, -0.3191988468170166]), ([-0.4023115932941437, -0.4033021926879883, -0.40340399742126465, -0.4033450186252594, -0.4033156931400299, -0.403335839509964, -0.40340089797973633, -0.4034293293952942, -0.4034660756587982, -0.4034944176673889, -0.4034918248653412], [-0.3194991648197174, -0.3194945454597473]), ([-0.40824830532073975, -0.40879419445991516, -0.40881600975990295, -0.4088096618652344, -0.40882551670074463, -0.4088156521320343, -0.4088279902935028, -0.4088518023490906, -0.4088595509529114, -0.408858984708786], [-0.31365394592285156, -0.3139486312866211]), ([-0.06754301488399506, -0.07287240028381348, -0.07292373478412628, -0.0729222521185875, -0.07292120903730392, -0.07293941080570221, -0.07296164333820343, -0.07298652082681656, -0.07299467921257019, -0.07299483567476273], [-0.22547930479049683, -0.22646670043468475]), ([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], [nan, nan])]\n"
          ]
        }
      ],
      "source": [
        "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
        "def defaul():\n",
        "    return defaultdict(list)\n",
        "\n",
        "\n",
        "def BAPG_torch(A, B, a=None, b=None, X=None, epoch=200, eps=1e-5, rho=1e-1):\n",
        "    if a is None:\n",
        "        #a = torch.ones([A.shape[0], 1], dtype=A.dtype).cuda()/A.shape[0]\n",
        "        a = torch.ones([A.shape[0], 1], dtype=A.dtype)/A.shape[0]\n",
        "    if b is None:\n",
        "        #b = torch.ones([B.shape[0], 1], dtype=A.dtype).cuda()/B.shape[0]\n",
        "        b = torch.ones([B.shape[0], 1], dtype=A.dtype)/B.shape[0]\n",
        "    if X is None:\n",
        "        X = a@b.T\n",
        "    obj_list, obj1_list, obj2_list, gap_list = [], [], [], []\n",
        "    for ii in range(epoch):\n",
        "        X = X + 1e-10\n",
        "        X = torch.exp(A@X@B/rho)*X\n",
        "        pi = X * (a / (X @ torch.ones_like(b)))\n",
        "        X = torch.exp(A@pi@B/rho)*pi\n",
        "        X = X * (b.T / (X.T @ torch.ones_like(a)).T)\n",
        "        if (ii+1) % 50 == 0:\n",
        "            objective = -torch.trace(A @ X @ B @ X.T).item()\n",
        "            X2 = (X+pi)/2\n",
        "            gap = (X2.sum(0)-b.squeeze(-1)).norm() + (X2.sum(1)-a.squeeze(-1)).norm()\n",
        "            gap_list.append(gap.item())\n",
        "            if len(obj_list) > 0 and np.abs((objective-obj_list[-1])/obj_list[-1]) < eps:\n",
        "                print('iter:{}, smaller than eps'.format(ii))\n",
        "                obj_list.append(objective)\n",
        "                break\n",
        "            obj_list.append(objective)\n",
        "    return X2, obj_list, gap_list\n",
        "\n",
        "\n",
        "def BAPG_numpy(A, B, a=None, b=None, X=None, epoch=200, eps=1e-5, rho=1e-1):\n",
        "    if a is None:\n",
        "        a = np.ones([A.shape[0], 1], dtype=A.dtype)/A.shape[0]\n",
        "    if b is None:\n",
        "        b = np.ones([B.shape[0], 1], dtype=A.dtype)/B.shape[0]\n",
        "    if X is None:\n",
        "        X = a@b.T\n",
        "    obj_list, gap_list = [], []\n",
        "    for ii in range(epoch):\n",
        "        X = X+1e-10\n",
        "        X = np.exp(A@X@B/rho)*X\n",
        "        pi = X * (a / (X @ np.ones_like(b)))\n",
        "        X = np.exp(A@pi@B/rho)*pi\n",
        "        X = X * (b.T / (X.T @ np.ones_like(a)).T)\n",
        "        if (ii+1) % 50 == 0:\n",
        "            X2 = (X+pi)/2\n",
        "            gap = np.linalg.norm((X2.sum(0)-b.squeeze(-1))) + np.linalg.norm(X2.sum(1)-a.squeeze(-1))\n",
        "            gap_list.append(gap.item())\n",
        "            objective = -np.trace(A @ X @ B @ X.T)\n",
        "            if len(obj_list) > 0 and np.abs((objective-obj_list[-1])/obj_list[-1]) < eps:\n",
        "                print('iter:{}, smaller than eps'.format(ii))\n",
        "                break\n",
        "            obj_list.append(objective)\n",
        "    return X2, obj_list, gap_list\n",
        "seed = 123\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "database = \"synthetic\"\n",
        "rho_list = [0.9, 0.5, 0.2, 0.1, 0.05, 0.01, 0.001]\n",
        "\n",
        "# parser = argparse.ArgumentParser()\n",
        "# parser.add_argument('--dataset', type=str, default='proteins', help='proteins / reddit / enzymes / synthetic')\n",
        "# parser.add_argument('--noise_level', type=float, default=0.)\n",
        "# parser.add_argument('--use_gpu', type=bool, default=False)\n",
        "# parser.add_argument('--loss_fun', type=str, default='square_loss', help='square_loss/kl_loss')\n",
        "# parser.add_argument('--rho', type=float, default=[0.5, 0.2, 0.1, 0.05, 0.01], nargs='+')\n",
        "\n",
        "# args = parser.parse_args()\n",
        "# rho_list = [0.5, 0.2, 0.1, 0.05, 0.01]\n",
        "# database = \"synthetic\"\n",
        "# noise_level = args.noise_level\n",
        "\n",
        "# if database == 'proteins':\n",
        "#     print('------------------Node Matching on PROTIENS---------------')\n",
        "#     with open('data/PROTEINS/matching.pk', 'rb') as f:\n",
        "#         graphs, _ = pickle.load(f)\n",
        "\n",
        "# if database == 'reddit':\n",
        "#     print('------------------Node Matching on REDDIT---------------')\n",
        "#     with open('data/REDDIT-BINARY/matching.pk', 'rb') as f:\n",
        "#         graphs = pickle.load(f)[:500]\n",
        "\n",
        "# if database == 'enzymes':\n",
        "#     print('------------------Node Matching on ENZYMES---------------')\n",
        "#     with open('data/ENZYMES/matching.pk', 'rb') as f:\n",
        "#         graphs = pickle.load(f)\n",
        "\n",
        "\n",
        "#ppppppppppppppppp\n",
        "\n",
        "# if database == 'synthetic':\n",
        "#     graphs, noise_graphs = [], []\n",
        "#     print('------------------Node Matching on Synthetic Database---------------')\n",
        "#     with open('graph1.pk', 'rb') as f:\n",
        "#         graph_pairs = pickle.load(f)\n",
        "#         print(graph_pairs)\n",
        "#         for num_node in [100]:\n",
        "#             for noise_level in [0.1]:\n",
        "#                 for G, G_noise in graph_pairs[(num_node, noise_level)]:\n",
        "#                     graphs.append(G)\n",
        "#                     noise_graphs.append(G_noise)\n",
        "\n",
        "#ppppppppppppppppp\n",
        "\n",
        "# if database != 'synthetic':\n",
        "#     if noise_level > 0:\n",
        "#         noise_graphs = []\n",
        "#         for G_src in graphs:\n",
        "#             G_dst = add_noisy_edges(G_src, noise_level)\n",
        "#             G_dst = add_noisy_nodes(G_dst, noise_level)\n",
        "#             noise_graphs.append(G_dst)\n",
        "#     else:\n",
        "#         noise_graphs = graphs\n",
        "\n",
        "#################\n",
        "\n",
        "\n",
        "# graphs = [ellipse_graph]\n",
        "# noise_graphs = [rotated_ellipse_graph]\n",
        "\n",
        "graphs = [G_english]\n",
        "\n",
        "noise_graphs = [G_russian]\n",
        "\n",
        "noise_level = 0.\n",
        "#################\n",
        "\n",
        "\n",
        "gap_rho = defaultdict(list)\n",
        "acc_rho = defaultdict(list)\n",
        "time_rho = defaultdict(list)\n",
        "gap2_rho = defaultdict(list)\n",
        "acc2_rho = defaultdict(list)\n",
        "time2_rho = defaultdict(list)\n",
        "obj_lists = []\n",
        "for j in range(len(graphs)):\n",
        "    print(j)\n",
        "    G = graphs[j]\n",
        "    G_noise = noise_graphs[j]\n",
        "    G_adj = nx.to_numpy_array(G).astype(np.float32)\n",
        "    G_adj_noise = nx.to_numpy_array(G_noise).astype(np.float32)\n",
        "    #G_adj_gpu = torch.tensor(G_adj).cuda()\n",
        "    G_adj_gpu = torch.tensor(G_adj)\n",
        "    #G_adj_noise_gpu = torch.tensor(G_adj_noise).cuda()\n",
        "    G_adj_noise_gpu = torch.tensor(G_adj_noise)\n",
        "    m, n = G_adj.shape[0], G_adj_noise.shape[0]\n",
        "    for rho in rho_list:  #0.5,0.2,0.1,0.05,\n",
        "        epoch = 2000 if rho < 0.2 else 4000\n",
        "        start = time.time()\n",
        "        # coup_bap, obj_list, gap_list = BAPG_numpy(\n",
        "        #     A=G_adj, B=G_adj_noise, epoch=2000, rho=rho, eps=1e-5, scaling=1.01, max_rho=0.5)\n",
        "        if True:\n",
        "            coup_bap, obj_list1, gap_list = BAPG_torch(\n",
        "                A=G_adj_gpu, B=G_adj_noise_gpu, epoch=epoch, rho=rho, eps=1e-5)\n",
        "            end = time.time()\n",
        "            acc = node_correctness(coup_bap.cpu().numpy(), np.eye(m))\n",
        "            print(rho, gap_list[-1], acc)\n",
        "            acc_rho[rho].append(acc)\n",
        "            time_rho[rho].append(end-start)\n",
        "            gap_rho[rho].append(gap_list[-1])\n",
        "            coup_bap, obj_list2, gap_list = BAPG_torch(\n",
        "                A=G_adj_gpu, B=G_adj_noise_gpu, X=coup_bap, epoch=100, rho=100, eps=1e-5)\n",
        "            end = time.time()\n",
        "            obj_lists.append((obj_list1, obj_list2))\n",
        "            acc = node_correctness(coup_bap.cpu().numpy(), np.eye(m))\n",
        "            print('100', gap_list[-1], acc)\n",
        "        else:\n",
        "            coup_bap, obj_list1, gap_list = BAPG_numpy(\n",
        "                A=G_adj, B=G_adj_noise, epoch=2000, rho=rho, eps=1e-5)\n",
        "            end = time.time()\n",
        "            print(\"fffff\")\n",
        "            print(obj_list1)\n",
        "            print(\"fffff\")\n",
        "            acc = node_correctness(coup_bap, np.eye(m))\n",
        "            print(rho, gap_list[-1], acc)\n",
        "            acc_rho[rho].append(acc)\n",
        "            time_rho[rho].append(end-start)\n",
        "            gap_rho[rho].append(gap_list[-1])\n",
        "            coup_bap, obj_list2, gap_list = BAPG_numpy(\n",
        "                A=G_adj, B=G_adj_noise, X=coup_bap, epoch=100, rho=100, eps=1e-5)\n",
        "            end = time.time()\n",
        "            obj_lists.append((obj_list1, obj_list2))\n",
        "            acc = node_correctness(coup_bap, np.eye(m))\n",
        "            print('100', gap_list[-1], acc)\n",
        "\n",
        "        acc2_rho[rho].append(acc)\n",
        "        time2_rho[rho].append(end-start)\n",
        "        gap2_rho[rho].append(gap_list[-1])\n",
        "\n",
        "\n",
        "for rho in rho_list:\n",
        "    print('rho:{},gap:{:.2e},acc:{:.5f},time:{:.1f},gap2:{:.2e},acc2:{:.5f},time2:{:.1f}'.format(\n",
        "        rho, np.mean(gap_rho[rho]), np.mean(acc_rho[rho])*100, np.sum(time_rho[rho]),\n",
        "        np.mean(gap2_rho[rho]), np.mean(acc2_rho[rho])*100, np.sum(time2_rho[rho])))\n",
        "\n",
        "    with open('result.txt', 'a+') as f:\n",
        "        f.write('Data:{},Noise:{},rho:{},gap:{:.2e},acc:{:.5f},time:{:.1f},gap2:{:.2e},acc2:{:.5f},time2:{:.1f}\\n'.format(\n",
        "            database, noise_level, rho, np.mean(gap_rho[rho]), np.mean(acc_rho[rho])*100, np.sum(time_rho[rho]),\n",
        "            np.mean(gap2_rho[rho]), np.mean(acc2_rho[rho])*100, np.sum(time2_rho[rho])))\n",
        "print('-'*10)\n",
        "print(type(G), type(G_noise), sep=\"    \")\n",
        "print('-'*3)\n",
        "print(type(G_adj), type(G_adj_noise), sep=\"    \")\n",
        "print('-'*10)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# nx.draw_networkx(G, with_labels=True, node_size=10, pos=nx.spring_layout(G), font_size=8, width=0.1)\n",
        "# plt.savefig(\"G.png\")\n",
        "# nx.draw_networkx(G_noise, with_labels=True, node_size=10, font_size=8, width=0.1)\n",
        "# plt.savefig(\"G_noise.png\")\n",
        "\n",
        "\n",
        "\n",
        "print('-'*10)\n",
        "print(obj_lists)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VMKpf80OKPGj",
        "outputId": "b6195aca-2293-44eb-c1a0-7840844905f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "iter:1199, smaller than eps\n",
            "0.9 0.003964466042816639 0.0\n",
            "100 0.00014171635848470032 0.0\n",
            "iter:1599, smaller than eps\n",
            "0.5 0.0056117926724255085 0.0\n",
            "100 0.00014000512601342052 0.0\n",
            "iter:1299, smaller than eps\n",
            "0.2 0.008394692093133926 0.002\n",
            "100 9.968025551643223e-05 0.002\n",
            "iter:799, smaller than eps\n",
            "0.1 0.012185841798782349 0.004\n",
            "100 8.160190191119909e-05 0.004\n",
            "iter:1199, smaller than eps\n",
            "0.05 0.017920464277267456 0.004\n",
            "100 6.901637243572623e-05 0.004\n",
            "iter:549, smaller than eps\n",
            "0.01 0.7641537189483643 0.002\n",
            "100 5.330513522494584e-05 0.002\n",
            "0.001 nan 0.002\n",
            "100 nan 0.002\n",
            "rho:0.9,gap:3.96e-03,acc:0.00000,time:21.5,gap2:1.42e-04,acc2:0.00000,time2:23.7\n",
            "rho:0.5,gap:5.61e-03,acc:0.00000,time:30.8,gap2:1.40e-04,acc2:0.00000,time2:32.4\n",
            "rho:0.2,gap:8.39e-03,acc:0.20000,time:23.8,gap2:9.97e-05,acc2:0.20000,time2:26.0\n",
            "rho:0.1,gap:1.22e-02,acc:0.40000,time:14.7,gap2:8.16e-05,acc2:0.40000,time2:16.4\n",
            "rho:0.05,gap:1.79e-02,acc:0.40000,time:21.5,gap2:6.90e-05,acc2:0.40000,time2:24.1\n",
            "rho:0.01,gap:7.64e-01,acc:0.20000,time:142.6,gap2:5.33e-05,acc2:0.20000,time2:145.3\n",
            "rho:0.001,gap:nan,acc:0.20000,time:43.3,gap2:nan,acc2:0.20000,time2:45.2\n",
            "----------\n",
            "<class 'networkx.classes.graph.Graph'>    <class 'networkx.classes.graph.Graph'>\n",
            "---\n",
            "<class 'numpy.ndarray'>    <class 'numpy.ndarray'>\n",
            "----------\n",
            "----------\n",
            "[([-0.32254353165626526, -0.364349901676178, -0.40017297863960266, -0.4188653528690338, -0.423627108335495, -0.42563575506210327, -0.4266797602176666, -0.42729079723358154, -0.4276832640171051, -0.42795124650001526, -0.428141713142395, -0.4282832741737366, -0.4283921420574188, -0.4284764528274536, -0.4285419285297394, -0.42859479784965515, -0.4286407232284546, -0.4286828935146332, -0.42872047424316406, -0.42875126004219055, -0.42877402901649475, -0.4287886917591095, -0.42879626154899597, -0.4287984073162079], [-0.39837419986724854, -0.3963386118412018]), ([-0.36215952038764954, -0.4229809045791626, -0.4319966733455658, -0.4345777630805969, -0.43579065799713135, -0.4365394711494446, -0.43702432513237, -0.43733981251716614, -0.4375550150871277, -0.4377073347568512, -0.4378111660480499, -0.4378731846809387, -0.4379045069217682, -0.43792709708213806, -0.43795984983444214, -0.4380042254924774, -0.43805214762687683, -0.438096821308136, -0.4381345808506012, -0.43816855549812317, -0.4381934702396393, -0.4382020831108093, -0.43819665908813477, -0.43818342685699463, -0.4381672143936157, -0.4381493628025055, -0.4381309747695923, -0.43811333179473877, -0.43809792399406433, -0.4380861222743988, -0.4380786120891571, -0.43807512521743774], [-0.3939533233642578, -0.39274150133132935]), ([-0.4388563930988312, -0.44445011019706726, -0.44554492831230164, -0.44589734077453613, -0.44613537192344666, -0.44636771082878113, -0.4465920925140381, -0.44677621126174927, -0.44690006971359253, -0.4470004439353943, -0.4471014142036438, -0.44718679785728455, -0.4472582936286926, -0.4473324120044708, -0.44740793108940125, -0.4475035071372986, -0.44761836528778076, -0.44766539335250854, -0.4476272761821747, -0.4475841522216797, -0.4475114941596985, -0.447386771440506, -0.44729724526405334, -0.4472310543060303, -0.44719213247299194, -0.4471931755542755], [-0.3897286355495453, -0.3894102871417999]), ([-0.45115405321121216, -0.4520547389984131, -0.45238783955574036, -0.45269426703453064, -0.45279666781425476, -0.4527667462825775, -0.4527246952056885, -0.4527832269668579, -0.4529460668563843, -0.4530777633190155, -0.4531315565109253, -0.4532240927219391, -0.4532375931739807, -0.4531555473804474, -0.4531286656856537, -0.453130304813385], [-0.38570255041122437, -0.38564977049827576]), ([-0.4540431499481201, -0.45456773042678833, -0.45474106073379517, -0.4547557234764099, -0.45481929183006287, -0.4550342857837677, -0.4551832377910614, -0.4553799331188202, -0.4553914964199066, -0.4554218351840973, -0.4555334448814392, -0.4559735059738159, -0.45626887679100037, -0.4563448131084442, -0.4562937915325165, -0.4562374949455261, -0.45609980821609497, -0.45598962903022766, -0.4559095501899719, -0.45580145716667175, -0.4557441473007202, -0.4558500647544861, -0.4558872580528259, -0.4558875858783722], [-0.3804053068161011, -0.3806842267513275]), ([-0.07041089236736298, -0.07048118859529495, -0.07044241577386856, -0.07045487314462662, -0.07046305388212204, -0.0704895630478859, -0.07050785422325134, -0.07055223733186722, -0.07056467235088348, -0.07056886702775955, -0.07056862115859985], [-0.2701892554759979, -0.27122458815574646]), ([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], [nan, nan])]\n"
          ]
        }
      ],
      "source": [
        "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
        "def defaul():\n",
        "    return defaultdict(list)\n",
        "\n",
        "\n",
        "def BAPG_torch(A, B, a=None, b=None, X=None, epoch=200, eps=1e-5, rho=1e-1):\n",
        "    if a is None:\n",
        "        #a = torch.ones([A.shape[0], 1], dtype=A.dtype).cuda()/A.shape[0]\n",
        "        a = torch.ones([A.shape[0], 1], dtype=A.dtype)/A.shape[0]\n",
        "    if b is None:\n",
        "        #b = torch.ones([B.shape[0], 1], dtype=A.dtype).cuda()/B.shape[0]\n",
        "        b = torch.ones([B.shape[0], 1], dtype=A.dtype)/B.shape[0]\n",
        "    if X is None:\n",
        "        X = a@b.T\n",
        "    obj_list, obj1_list, obj2_list, gap_list = [], [], [], []\n",
        "    for ii in range(epoch):\n",
        "        X = X + 1e-10\n",
        "        X = torch.exp(A@X@B/rho)*X\n",
        "        pi = X * (a / (X @ torch.ones_like(b)))\n",
        "        X = torch.exp(A@pi@B/rho)*pi\n",
        "        X = X * (b.T / (X.T @ torch.ones_like(a)).T)\n",
        "        if (ii+1) % 50 == 0:\n",
        "            objective = -torch.trace(A @ X @ B @ X.T).item()\n",
        "            X2 = (X+pi)/2\n",
        "            gap = (X2.sum(0)-b.squeeze(-1)).norm() + (X2.sum(1)-a.squeeze(-1)).norm()\n",
        "            gap_list.append(gap.item())\n",
        "            if len(obj_list) > 0 and np.abs((objective-obj_list[-1])/obj_list[-1]) < eps:\n",
        "                print('iter:{}, smaller than eps'.format(ii))\n",
        "                obj_list.append(objective)\n",
        "                break\n",
        "            obj_list.append(objective)\n",
        "    return X2, obj_list, gap_list\n",
        "\n",
        "\n",
        "def BAPG_numpy(A, B, a=None, b=None, X=None, epoch=200, eps=1e-5, rho=1e-1):\n",
        "    if a is None:\n",
        "        a = np.ones([A.shape[0], 1], dtype=A.dtype)/A.shape[0]\n",
        "    if b is None:\n",
        "        b = np.ones([B.shape[0], 1], dtype=A.dtype)/B.shape[0]\n",
        "    if X is None:\n",
        "        X = a@b.T\n",
        "    obj_list, gap_list = [], []\n",
        "    for ii in range(epoch):\n",
        "        X = X+1e-10\n",
        "        X = np.exp(A@X@B/rho)*X\n",
        "        pi = X * (a / (X @ np.ones_like(b)))\n",
        "        X = np.exp(A@pi@B/rho)*pi\n",
        "        X = X * (b.T / (X.T @ np.ones_like(a)).T)\n",
        "        if (ii+1) % 50 == 0:\n",
        "            X2 = (X+pi)/2\n",
        "            gap = np.linalg.norm((X2.sum(0)-b.squeeze(-1))) + np.linalg.norm(X2.sum(1)-a.squeeze(-1))\n",
        "            gap_list.append(gap.item())\n",
        "            objective = -np.trace(A @ X @ B @ X.T)\n",
        "            if len(obj_list) > 0 and np.abs((objective-obj_list[-1])/obj_list[-1]) < eps:\n",
        "                print('iter:{}, smaller than eps'.format(ii))\n",
        "                break\n",
        "            obj_list.append(objective)\n",
        "    return X2, obj_list, gap_list\n",
        "seed = 123\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "database = \"synthetic\"\n",
        "rho_list = [0.9, 0.5, 0.2, 0.1, 0.05, 0.01, 0.001]\n",
        "\n",
        "# parser = argparse.ArgumentParser()\n",
        "# parser.add_argument('--dataset', type=str, default='proteins', help='proteins / reddit / enzymes / synthetic')\n",
        "# parser.add_argument('--noise_level', type=float, default=0.)\n",
        "# parser.add_argument('--use_gpu', type=bool, default=False)\n",
        "# parser.add_argument('--loss_fun', type=str, default='square_loss', help='square_loss/kl_loss')\n",
        "# parser.add_argument('--rho', type=float, default=[0.5, 0.2, 0.1, 0.05, 0.01], nargs='+')\n",
        "\n",
        "# args = parser.parse_args()\n",
        "# rho_list = [0.5, 0.2, 0.1, 0.05, 0.01]\n",
        "# database = \"synthetic\"\n",
        "# noise_level = args.noise_level\n",
        "\n",
        "# if database == 'proteins':\n",
        "#     print('------------------Node Matching on PROTIENS---------------')\n",
        "#     with open('data/PROTEINS/matching.pk', 'rb') as f:\n",
        "#         graphs, _ = pickle.load(f)\n",
        "\n",
        "# if database == 'reddit':\n",
        "#     print('------------------Node Matching on REDDIT---------------')\n",
        "#     with open('data/REDDIT-BINARY/matching.pk', 'rb') as f:\n",
        "#         graphs = pickle.load(f)[:500]\n",
        "\n",
        "# if database == 'enzymes':\n",
        "#     print('------------------Node Matching on ENZYMES---------------')\n",
        "#     with open('data/ENZYMES/matching.pk', 'rb') as f:\n",
        "#         graphs = pickle.load(f)\n",
        "\n",
        "\n",
        "#ppppppppppppppppp\n",
        "\n",
        "# if database == 'synthetic':\n",
        "#     graphs, noise_graphs = [], []\n",
        "#     print('------------------Node Matching on Synthetic Database---------------')\n",
        "#     with open('graph1.pk', 'rb') as f:\n",
        "#         graph_pairs = pickle.load(f)\n",
        "#         print(graph_pairs)\n",
        "#         for num_node in [100]:\n",
        "#             for noise_level in [0.1]:\n",
        "#                 for G, G_noise in graph_pairs[(num_node, noise_level)]:\n",
        "#                     graphs.append(G)\n",
        "#                     noise_graphs.append(G_noise)\n",
        "\n",
        "#ppppppppppppppppp\n",
        "\n",
        "# if database != 'synthetic':\n",
        "#     if noise_level > 0:\n",
        "#         noise_graphs = []\n",
        "#         for G_src in graphs:\n",
        "#             G_dst = add_noisy_edges(G_src, noise_level)\n",
        "#             G_dst = add_noisy_nodes(G_dst, noise_level)\n",
        "#             noise_graphs.append(G_dst)\n",
        "#     else:\n",
        "#         noise_graphs = graphs\n",
        "\n",
        "#################\n",
        "\n",
        "\n",
        "# graphs = [ellipse_graph]\n",
        "# noise_graphs = [rotated_ellipse_graph]\n",
        "\n",
        "graphs = [G_french]\n",
        "\n",
        "noise_graphs = [G_german]\n",
        "\n",
        "noise_level = 0.\n",
        "#################\n",
        "\n",
        "\n",
        "gap_rho = defaultdict(list)\n",
        "acc_rho = defaultdict(list)\n",
        "time_rho = defaultdict(list)\n",
        "gap2_rho = defaultdict(list)\n",
        "acc2_rho = defaultdict(list)\n",
        "time2_rho = defaultdict(list)\n",
        "obj_lists = []\n",
        "for j in range(len(graphs)):\n",
        "    print(j)\n",
        "    G = graphs[j]\n",
        "    G_noise = noise_graphs[j]\n",
        "    G_adj = nx.to_numpy_array(G).astype(np.float32)\n",
        "    G_adj_noise = nx.to_numpy_array(G_noise).astype(np.float32)\n",
        "    #G_adj_gpu = torch.tensor(G_adj).cuda()\n",
        "    G_adj_gpu = torch.tensor(G_adj)\n",
        "    #G_adj_noise_gpu = torch.tensor(G_adj_noise).cuda()\n",
        "    G_adj_noise_gpu = torch.tensor(G_adj_noise)\n",
        "    m, n = G_adj.shape[0], G_adj_noise.shape[0]\n",
        "    for rho in rho_list:  #0.5,0.2,0.1,0.05,\n",
        "        epoch = 2000 if rho < 0.2 else 4000\n",
        "        start = time.time()\n",
        "        # coup_bap, obj_list, gap_list = BAPG_numpy(\n",
        "        #     A=G_adj, B=G_adj_noise, epoch=2000, rho=rho, eps=1e-5, scaling=1.01, max_rho=0.5)\n",
        "        if True:\n",
        "            coup_bap, obj_list1, gap_list = BAPG_torch(\n",
        "                A=G_adj_gpu, B=G_adj_noise_gpu, epoch=epoch, rho=rho, eps=1e-5)\n",
        "            end = time.time()\n",
        "            acc = node_correctness(coup_bap.cpu().numpy(), np.eye(m))\n",
        "            print(rho, gap_list[-1], acc)\n",
        "            acc_rho[rho].append(acc)\n",
        "            time_rho[rho].append(end-start)\n",
        "            gap_rho[rho].append(gap_list[-1])\n",
        "            coup_bap, obj_list2, gap_list = BAPG_torch(\n",
        "                A=G_adj_gpu, B=G_adj_noise_gpu, X=coup_bap, epoch=100, rho=100, eps=1e-5)\n",
        "            end = time.time()\n",
        "            obj_lists.append((obj_list1, obj_list2))\n",
        "            acc = node_correctness(coup_bap.cpu().numpy(), np.eye(m))\n",
        "            print('100', gap_list[-1], acc)\n",
        "        else:\n",
        "            coup_bap, obj_list1, gap_list = BAPG_numpy(\n",
        "                A=G_adj, B=G_adj_noise, epoch=2000, rho=rho, eps=1e-5)\n",
        "            end = time.time()\n",
        "            print(\"fffff\")\n",
        "            print(obj_list1)\n",
        "            print(\"fffff\")\n",
        "            acc = node_correctness(coup_bap, np.eye(m))\n",
        "            print(rho, gap_list[-1], acc)\n",
        "            acc_rho[rho].append(acc)\n",
        "            time_rho[rho].append(end-start)\n",
        "            gap_rho[rho].append(gap_list[-1])\n",
        "            coup_bap, obj_list2, gap_list = BAPG_numpy(\n",
        "                A=G_adj, B=G_adj_noise, X=coup_bap, epoch=100, rho=100, eps=1e-5)\n",
        "            end = time.time()\n",
        "            obj_lists.append((obj_list1, obj_list2))\n",
        "            acc = node_correctness(coup_bap, np.eye(m))\n",
        "            print('100', gap_list[-1], acc)\n",
        "\n",
        "        acc2_rho[rho].append(acc)\n",
        "        time2_rho[rho].append(end-start)\n",
        "        gap2_rho[rho].append(gap_list[-1])\n",
        "\n",
        "\n",
        "for rho in rho_list:\n",
        "    print('rho:{},gap:{:.2e},acc:{:.5f},time:{:.1f},gap2:{:.2e},acc2:{:.5f},time2:{:.1f}'.format(\n",
        "        rho, np.mean(gap_rho[rho]), np.mean(acc_rho[rho])*100, np.sum(time_rho[rho]),\n",
        "        np.mean(gap2_rho[rho]), np.mean(acc2_rho[rho])*100, np.sum(time2_rho[rho])))\n",
        "\n",
        "    with open('result.txt', 'a+') as f:\n",
        "        f.write('Data:{},Noise:{},rho:{},gap:{:.2e},acc:{:.5f},time:{:.1f},gap2:{:.2e},acc2:{:.5f},time2:{:.1f}\\n'.format(\n",
        "            database, noise_level, rho, np.mean(gap_rho[rho]), np.mean(acc_rho[rho])*100, np.sum(time_rho[rho]),\n",
        "            np.mean(gap2_rho[rho]), np.mean(acc2_rho[rho])*100, np.sum(time2_rho[rho])))\n",
        "print('-'*10)\n",
        "print(type(G), type(G_noise), sep=\"    \")\n",
        "print('-'*3)\n",
        "print(type(G_adj), type(G_adj_noise), sep=\"    \")\n",
        "print('-'*10)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# nx.draw_networkx(G, with_labels=True, node_size=10, pos=nx.spring_layout(G), font_size=8, width=0.1)\n",
        "# plt.savefig(\"G.png\")\n",
        "# nx.draw_networkx(G_noise, with_labels=True, node_size=10, font_size=8, width=0.1)\n",
        "# plt.savefig(\"G_noise.png\")\n",
        "\n",
        "\n",
        "\n",
        "print('-'*10)\n",
        "print(obj_lists)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PU5QMbvmKPp_",
        "outputId": "2eb26cad-091a-43e6-bb5e-61db55e9a8e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "iter:1999, smaller than eps\n",
            "0.9 0.0015654730377718806 0.004\n",
            "100 0.00036059663398191333 0.004\n",
            "iter:699, smaller than eps\n",
            "0.5 0.0023868137504905462 0.004\n",
            "100 0.0002942407736554742 0.002\n",
            "iter:849, smaller than eps\n",
            "0.2 0.005200449842959642 0.004\n",
            "100 0.00018080903100781143 0.004\n",
            "iter:1249, smaller than eps\n",
            "0.1 0.009510001167654991 0.008\n",
            "100 0.00013590148591902107 0.008\n",
            "iter:1299, smaller than eps\n",
            "0.05 0.015729378908872604 0.004\n",
            "100 0.00012627022806555033 0.004\n",
            "iter:349, smaller than eps\n",
            "0.01 0.7380968332290649 0.002\n",
            "100 5.6780198065098375e-05 0.004\n",
            "0.001 nan 0.002\n",
            "100 nan 0.002\n",
            "rho:0.9,gap:1.57e-03,acc:0.40000,time:36.9,gap2:3.61e-04,acc2:0.40000,time2:38.5\n",
            "rho:0.5,gap:2.39e-03,acc:0.40000,time:13.0,gap2:2.94e-04,acc2:0.20000,time2:14.7\n",
            "rho:0.2,gap:5.20e-03,acc:0.40000,time:15.5,gap2:1.81e-04,acc2:0.40000,time2:17.2\n",
            "rho:0.1,gap:9.51e-03,acc:0.80000,time:23.3,gap2:1.36e-04,acc2:0.80000,time2:25.0\n",
            "rho:0.05,gap:1.57e-02,acc:0.40000,time:24.2,gap2:1.26e-04,acc2:0.40000,time2:25.9\n",
            "rho:0.01,gap:7.38e-01,acc:0.20000,time:103.0,gap2:5.68e-05,acc2:0.40000,time2:104.9\n",
            "rho:0.001,gap:nan,acc:0.20000,time:43.5,gap2:nan,acc2:0.20000,time2:45.4\n",
            "----------\n",
            "<class 'networkx.classes.graph.Graph'>    <class 'networkx.classes.graph.Graph'>\n",
            "---\n",
            "<class 'numpy.ndarray'>    <class 'numpy.ndarray'>\n",
            "----------\n",
            "----------\n",
            "[([-0.30584028363227844, -0.34843310713768005, -0.3841679096221924, -0.3923216760158539, -0.3951970934867859, -0.3965648114681244, -0.3973422944545746, -0.39783453941345215, -0.3981717526912689, -0.39841705560684204, -0.39860421419143677, -0.398751825094223, -0.39886969327926636, -0.3989645540714264, -0.3990420401096344, -0.3991064727306366, -0.3991602957248688, -0.39920440316200256, -0.399239182472229, -0.3992657959461212, -0.3992866575717926, -0.39930441975593567, -0.39932096004486084, -0.39933711290359497, -0.39935290813446045, -0.39936789870262146, -0.3993816375732422, -0.39939364790916443, -0.3994053602218628, -0.39941906929016113, -0.3994341194629669, -0.39944881200790405, -0.3994618356227875, -0.3994726538658142, -0.39948129653930664, -0.399488240480423, -0.399493932723999, -0.39949870109558105, -0.3995027542114258, -0.39950624108314514], [-0.39741164445877075, -0.3926258087158203]), ([-0.3398192524909973, -0.39198166131973267, -0.39794591069221497, -0.399558424949646, -0.40021592378616333, -0.40053948760032654, -0.4007168114185333, -0.40081986784935, -0.400870680809021, -0.40089151263237, -0.4009028971195221, -0.4009122848510742, -0.4009181261062622, -0.4009217619895935], [-0.3969723880290985, -0.39117974042892456]), ([-0.39967280626296997, -0.40397971868515015, -0.4045463502407074, -0.40471330285072327, -0.4047815799713135, -0.4048551023006439, -0.40492308139801025, -0.4049335718154907, -0.4048957824707031, -0.40485119819641113, -0.40480828285217285, -0.4047999083995819, -0.4048161208629608, -0.40484288334846497, -0.40486380457878113, -0.4048692286014557, -0.40486717224121094], [-0.3911403715610504, -0.3882092237472534]), ([-0.40752655267715454, -0.4082412123680115, -0.40827804803848267, -0.40827226638793945, -0.4082801938056946, -0.40832629799842834, -0.4083958864212036, -0.4084317088127136, -0.4084487557411194, -0.4084562361240387, -0.40845006704330444, -0.4084324836730957, -0.40841013193130493, -0.40838146209716797, -0.4083470404148102, -0.40831705927848816, -0.408298134803772, -0.40828800201416016, -0.40827998518943787, -0.4082708954811096, -0.4082609713077545, -0.40825265645980835, -0.40824639797210693, -0.40824171900749207, -0.4082382321357727], [-0.38494235277175903, -0.3842371106147766]), ([-0.4127408564090729, -0.4131302237510681, -0.4132804274559021, -0.4132857620716095, -0.4132450819015503, -0.4132743179798126, -0.4133228361606598, -0.41334664821624756, -0.4133242070674896, -0.4133424162864685, -0.41330933570861816, -0.41327959299087524, -0.41324326395988464, -0.4132189452648163, -0.41321438550949097, -0.4132217764854431, -0.4132446050643921, -0.4132836163043976, -0.41331395506858826, -0.4133267402648926, -0.4133419990539551, -0.41336050629615784, -0.41336899995803833, -0.4133490025997162, -0.41331854462623596, -0.4133172035217285], [-0.3768281638622284, -0.3765263259410858]), ([-0.06224068999290466, -0.06227511912584305, -0.06226462498307228, -0.06227004528045654, -0.062263764441013336, -0.06225680187344551, -0.06225667893886566], [-0.268545538187027, -0.26899755001068115]), ([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], [nan, nan])]\n"
          ]
        }
      ],
      "source": [
        "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
        "def defaul():\n",
        "    return defaultdict(list)\n",
        "\n",
        "\n",
        "def BAPG_torch(A, B, a=None, b=None, X=None, epoch=200, eps=1e-5, rho=1e-1):\n",
        "    if a is None:\n",
        "        #a = torch.ones([A.shape[0], 1], dtype=A.dtype).cuda()/A.shape[0]\n",
        "        a = torch.ones([A.shape[0], 1], dtype=A.dtype)/A.shape[0]\n",
        "    if b is None:\n",
        "        #b = torch.ones([B.shape[0], 1], dtype=A.dtype).cuda()/B.shape[0]\n",
        "        b = torch.ones([B.shape[0], 1], dtype=A.dtype)/B.shape[0]\n",
        "    if X is None:\n",
        "        X = a@b.T\n",
        "    obj_list, obj1_list, obj2_list, gap_list = [], [], [], []\n",
        "    for ii in range(epoch):\n",
        "        X = X + 1e-10\n",
        "        X = torch.exp(A@X@B/rho)*X\n",
        "        pi = X * (a / (X @ torch.ones_like(b)))\n",
        "        X = torch.exp(A@pi@B/rho)*pi\n",
        "        X = X * (b.T / (X.T @ torch.ones_like(a)).T)\n",
        "        if (ii+1) % 50 == 0:\n",
        "            objective = -torch.trace(A @ X @ B @ X.T).item()\n",
        "            X2 = (X+pi)/2\n",
        "            gap = (X2.sum(0)-b.squeeze(-1)).norm() + (X2.sum(1)-a.squeeze(-1)).norm()\n",
        "            gap_list.append(gap.item())\n",
        "            if len(obj_list) > 0 and np.abs((objective-obj_list[-1])/obj_list[-1]) < eps:\n",
        "                print('iter:{}, smaller than eps'.format(ii))\n",
        "                obj_list.append(objective)\n",
        "                break\n",
        "            obj_list.append(objective)\n",
        "    return X2, obj_list, gap_list\n",
        "\n",
        "\n",
        "def BAPG_numpy(A, B, a=None, b=None, X=None, epoch=200, eps=1e-5, rho=1e-1):\n",
        "    if a is None:\n",
        "        a = np.ones([A.shape[0], 1], dtype=A.dtype)/A.shape[0]\n",
        "    if b is None:\n",
        "        b = np.ones([B.shape[0], 1], dtype=A.dtype)/B.shape[0]\n",
        "    if X is None:\n",
        "        X = a@b.T\n",
        "    obj_list, gap_list = [], []\n",
        "    for ii in range(epoch):\n",
        "        X = X+1e-10\n",
        "        X = np.exp(A@X@B/rho)*X\n",
        "        pi = X * (a / (X @ np.ones_like(b)))\n",
        "        X = np.exp(A@pi@B/rho)*pi\n",
        "        X = X * (b.T / (X.T @ np.ones_like(a)).T)\n",
        "        if (ii+1) % 50 == 0:\n",
        "            X2 = (X+pi)/2\n",
        "            gap = np.linalg.norm((X2.sum(0)-b.squeeze(-1))) + np.linalg.norm(X2.sum(1)-a.squeeze(-1))\n",
        "            gap_list.append(gap.item())\n",
        "            objective = -np.trace(A @ X @ B @ X.T)\n",
        "            if len(obj_list) > 0 and np.abs((objective-obj_list[-1])/obj_list[-1]) < eps:\n",
        "                print('iter:{}, smaller than eps'.format(ii))\n",
        "                break\n",
        "            obj_list.append(objective)\n",
        "    return X2, obj_list, gap_list\n",
        "seed = 123\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "database = \"synthetic\"\n",
        "rho_list = [0.9, 0.5, 0.2, 0.1, 0.05, 0.01, 0.001]\n",
        "\n",
        "# parser = argparse.ArgumentParser()\n",
        "# parser.add_argument('--dataset', type=str, default='proteins', help='proteins / reddit / enzymes / synthetic')\n",
        "# parser.add_argument('--noise_level', type=float, default=0.)\n",
        "# parser.add_argument('--use_gpu', type=bool, default=False)\n",
        "# parser.add_argument('--loss_fun', type=str, default='square_loss', help='square_loss/kl_loss')\n",
        "# parser.add_argument('--rho', type=float, default=[0.5, 0.2, 0.1, 0.05, 0.01], nargs='+')\n",
        "\n",
        "# args = parser.parse_args()\n",
        "# rho_list = [0.5, 0.2, 0.1, 0.05, 0.01]\n",
        "# database = \"synthetic\"\n",
        "# noise_level = args.noise_level\n",
        "\n",
        "# if database == 'proteins':\n",
        "#     print('------------------Node Matching on PROTIENS---------------')\n",
        "#     with open('data/PROTEINS/matching.pk', 'rb') as f:\n",
        "#         graphs, _ = pickle.load(f)\n",
        "\n",
        "# if database == 'reddit':\n",
        "#     print('------------------Node Matching on REDDIT---------------')\n",
        "#     with open('data/REDDIT-BINARY/matching.pk', 'rb') as f:\n",
        "#         graphs = pickle.load(f)[:500]\n",
        "\n",
        "# if database == 'enzymes':\n",
        "#     print('------------------Node Matching on ENZYMES---------------')\n",
        "#     with open('data/ENZYMES/matching.pk', 'rb') as f:\n",
        "#         graphs = pickle.load(f)\n",
        "\n",
        "\n",
        "#ppppppppppppppppp\n",
        "\n",
        "# if database == 'synthetic':\n",
        "#     graphs, noise_graphs = [], []\n",
        "#     print('------------------Node Matching on Synthetic Database---------------')\n",
        "#     with open('graph1.pk', 'rb') as f:\n",
        "#         graph_pairs = pickle.load(f)\n",
        "#         print(graph_pairs)\n",
        "#         for num_node in [100]:\n",
        "#             for noise_level in [0.1]:\n",
        "#                 for G, G_noise in graph_pairs[(num_node, noise_level)]:\n",
        "#                     graphs.append(G)\n",
        "#                     noise_graphs.append(G_noise)\n",
        "\n",
        "#ppppppppppppppppp\n",
        "\n",
        "# if database != 'synthetic':\n",
        "#     if noise_level > 0:\n",
        "#         noise_graphs = []\n",
        "#         for G_src in graphs:\n",
        "#             G_dst = add_noisy_edges(G_src, noise_level)\n",
        "#             G_dst = add_noisy_nodes(G_dst, noise_level)\n",
        "#             noise_graphs.append(G_dst)\n",
        "#     else:\n",
        "#         noise_graphs = graphs\n",
        "\n",
        "#################\n",
        "\n",
        "\n",
        "# graphs = [ellipse_graph]\n",
        "# noise_graphs = [rotated_ellipse_graph]\n",
        "\n",
        "graphs = [G_french]\n",
        "\n",
        "noise_graphs = [G_russian]\n",
        "\n",
        "noise_level = 0.\n",
        "#################\n",
        "\n",
        "\n",
        "gap_rho = defaultdict(list)\n",
        "acc_rho = defaultdict(list)\n",
        "time_rho = defaultdict(list)\n",
        "gap2_rho = defaultdict(list)\n",
        "acc2_rho = defaultdict(list)\n",
        "time2_rho = defaultdict(list)\n",
        "obj_lists = []\n",
        "for j in range(len(graphs)):\n",
        "    print(j)\n",
        "    G = graphs[j]\n",
        "    G_noise = noise_graphs[j]\n",
        "    G_adj = nx.to_numpy_array(G).astype(np.float32)\n",
        "    G_adj_noise = nx.to_numpy_array(G_noise).astype(np.float32)\n",
        "    #G_adj_gpu = torch.tensor(G_adj).cuda()\n",
        "    G_adj_gpu = torch.tensor(G_adj)\n",
        "    #G_adj_noise_gpu = torch.tensor(G_adj_noise).cuda()\n",
        "    G_adj_noise_gpu = torch.tensor(G_adj_noise)\n",
        "    m, n = G_adj.shape[0], G_adj_noise.shape[0]\n",
        "    for rho in rho_list:  #0.5,0.2,0.1,0.05,\n",
        "        epoch = 2000 if rho < 0.2 else 4000\n",
        "        start = time.time()\n",
        "        # coup_bap, obj_list, gap_list = BAPG_numpy(\n",
        "        #     A=G_adj, B=G_adj_noise, epoch=2000, rho=rho, eps=1e-5, scaling=1.01, max_rho=0.5)\n",
        "        if True:\n",
        "            coup_bap, obj_list1, gap_list = BAPG_torch(\n",
        "                A=G_adj_gpu, B=G_adj_noise_gpu, epoch=epoch, rho=rho, eps=1e-5)\n",
        "            end = time.time()\n",
        "            acc = node_correctness(coup_bap.cpu().numpy(), np.eye(m))\n",
        "            print(rho, gap_list[-1], acc)\n",
        "            acc_rho[rho].append(acc)\n",
        "            time_rho[rho].append(end-start)\n",
        "            gap_rho[rho].append(gap_list[-1])\n",
        "            coup_bap, obj_list2, gap_list = BAPG_torch(\n",
        "                A=G_adj_gpu, B=G_adj_noise_gpu, X=coup_bap, epoch=100, rho=100, eps=1e-5)\n",
        "            end = time.time()\n",
        "            obj_lists.append((obj_list1, obj_list2))\n",
        "            acc = node_correctness(coup_bap.cpu().numpy(), np.eye(m))\n",
        "            print('100', gap_list[-1], acc)\n",
        "        else:\n",
        "            coup_bap, obj_list1, gap_list = BAPG_numpy(\n",
        "                A=G_adj, B=G_adj_noise, epoch=2000, rho=rho, eps=1e-5)\n",
        "            end = time.time()\n",
        "            print(\"fffff\")\n",
        "            print(obj_list1)\n",
        "            print(\"fffff\")\n",
        "            acc = node_correctness(coup_bap, np.eye(m))\n",
        "            print(rho, gap_list[-1], acc)\n",
        "            acc_rho[rho].append(acc)\n",
        "            time_rho[rho].append(end-start)\n",
        "            gap_rho[rho].append(gap_list[-1])\n",
        "            coup_bap, obj_list2, gap_list = BAPG_numpy(\n",
        "                A=G_adj, B=G_adj_noise, X=coup_bap, epoch=100, rho=100, eps=1e-5)\n",
        "            end = time.time()\n",
        "            obj_lists.append((obj_list1, obj_list2))\n",
        "            acc = node_correctness(coup_bap, np.eye(m))\n",
        "            print('100', gap_list[-1], acc)\n",
        "\n",
        "        acc2_rho[rho].append(acc)\n",
        "        time2_rho[rho].append(end-start)\n",
        "        gap2_rho[rho].append(gap_list[-1])\n",
        "\n",
        "\n",
        "for rho in rho_list:\n",
        "    print('rho:{},gap:{:.2e},acc:{:.5f},time:{:.1f},gap2:{:.2e},acc2:{:.5f},time2:{:.1f}'.format(\n",
        "        rho, np.mean(gap_rho[rho]), np.mean(acc_rho[rho])*100, np.sum(time_rho[rho]),\n",
        "        np.mean(gap2_rho[rho]), np.mean(acc2_rho[rho])*100, np.sum(time2_rho[rho])))\n",
        "\n",
        "    with open('result.txt', 'a+') as f:\n",
        "        f.write('Data:{},Noise:{},rho:{},gap:{:.2e},acc:{:.5f},time:{:.1f},gap2:{:.2e},acc2:{:.5f},time2:{:.1f}\\n'.format(\n",
        "            database, noise_level, rho, np.mean(gap_rho[rho]), np.mean(acc_rho[rho])*100, np.sum(time_rho[rho]),\n",
        "            np.mean(gap2_rho[rho]), np.mean(acc2_rho[rho])*100, np.sum(time2_rho[rho])))\n",
        "print('-'*10)\n",
        "print(type(G), type(G_noise), sep=\"    \")\n",
        "print('-'*3)\n",
        "print(type(G_adj), type(G_adj_noise), sep=\"    \")\n",
        "print('-'*10)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# nx.draw_networkx(G, with_labels=True, node_size=10, pos=nx.spring_layout(G), font_size=8, width=0.1)\n",
        "# plt.savefig(\"G.png\")\n",
        "# nx.draw_networkx(G_noise, with_labels=True, node_size=10, font_size=8, width=0.1)\n",
        "# plt.savefig(\"G_noise.png\")\n",
        "\n",
        "\n",
        "\n",
        "print('-'*10)\n",
        "print(obj_lists)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "QzplMQwZKQOt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34c6bc75-0f66-4ccd-e8a0-586c73c85160"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "iter:2099, smaller than eps\n",
            "0.9 0.0031573474407196045 0.002\n",
            "100 0.00016901249182410538 0.002\n",
            "iter:699, smaller than eps\n",
            "0.5 0.004462127108126879 0.0\n",
            "100 0.00015142644406296313 0.0\n",
            "iter:449, smaller than eps\n",
            "0.2 0.007133902050554752 0.0\n",
            "100 0.00011220475425943732 0.0\n",
            "iter:1099, smaller than eps\n",
            "0.1 0.010953596793115139 0.0\n",
            "100 7.700316200498492e-05 0.0\n",
            "iter:549, smaller than eps\n",
            "0.05 0.016464710235595703 0.002\n",
            "100 7.035435555735603e-05 0.002\n",
            "iter:349, smaller than eps\n",
            "0.01 0.7681795358657837 0.002\n",
            "100 5.064034485258162e-05 0.002\n",
            "0.001 nan 0.002\n",
            "100 nan 0.002\n",
            "rho:0.9,gap:3.16e-03,acc:0.20000,time:40.4,gap2:1.69e-04,acc2:0.20000,time2:42.1\n",
            "rho:0.5,gap:4.46e-03,acc:0.00000,time:13.1,gap2:1.51e-04,acc2:0.00000,time2:14.8\n",
            "rho:0.2,gap:7.13e-03,acc:0.00000,time:9.3,gap2:1.12e-04,acc2:0.00000,time2:11.0\n",
            "rho:0.1,gap:1.10e-02,acc:0.00000,time:19.8,gap2:7.70e-05,acc2:0.00000,time2:22.6\n",
            "rho:0.05,gap:1.65e-02,acc:0.20000,time:9.4,gap2:7.04e-05,acc2:0.20000,time2:11.0\n",
            "rho:0.01,gap:7.68e-01,acc:0.20000,time:119.4,gap2:5.06e-05,acc2:0.20000,time2:121.1\n",
            "rho:0.001,gap:nan,acc:0.20000,time:45.8,gap2:nan,acc2:0.20000,time2:47.9\n",
            "----------\n",
            "<class 'networkx.classes.graph.Graph'>    <class 'networkx.classes.graph.Graph'>\n",
            "---\n",
            "<class 'numpy.ndarray'>    <class 'numpy.ndarray'>\n",
            "----------\n",
            "----------\n",
            "[([-0.32316654920578003, -0.36179280281066895, -0.3977680802345276, -0.40622442960739136, -0.40886279940605164, -0.4100733995437622, -0.41077372431755066, -0.4112361669540405, -0.41156405210494995, -0.4118061661720276, -0.41199126839637756, -0.41213688254356384, -0.41225412487983704, -0.41235122084617615, -0.41243430972099304, -0.41250771284103394, -0.4125742018222809, -0.41263553500175476, -0.4126926064491272, -0.4127458333969116, -0.4127950966358185, -0.4128401279449463, -0.4128807783126831, -0.4129171073436737, -0.4129495322704315, -0.4129786491394043, -0.4130048453807831, -0.4130285382270813, -0.41304999589920044, -0.41306939721107483, -0.41308698058128357, -0.4131028950214386, -0.413117378950119, -0.4131305515766144, -0.41314250230789185, -0.41315314173698425, -0.4131624400615692, -0.4131704568862915, -0.4131772518157959, -0.4131828248500824, -0.41318726539611816, -0.41319069266319275], [-0.4124501347541809, -0.4121561646461487]), ([-0.35471391677856445, -0.40303024649620056, -0.4082363247871399, -0.40960240364074707, -0.4102265238761902, -0.41057223081588745, -0.4107748568058014, -0.4109000563621521, -0.4109872579574585, -0.41104909777641296, -0.41108790040016174, -0.41110673546791077, -0.41111239790916443, -0.41111430525779724], [-0.40990495681762695, -0.4095924496650696]), ([-0.40625953674316406, -0.40967220067977905, -0.4101676344871521, -0.41036954522132874, -0.4104951322078705, -0.41057583689689636, -0.41061097383499146, -0.41062140464782715, -0.4106203317642212], [-0.4070788025856018, -0.406739205121994]), ([-0.4113275706768036, -0.4119620621204376, -0.4120652973651886, -0.41210028529167175, -0.4121658504009247, -0.41223013401031494, -0.4122716188430786, -0.4122973084449768, -0.4123154580593109, -0.412331223487854, -0.41234302520751953, -0.4123506546020508, -0.41235867142677307, -0.4123659133911133, -0.4123725891113281, -0.41237983107566833, -0.4123862683773041, -0.41239169239997864, -0.41239699721336365, -0.4124036431312561, -0.4124099016189575, -0.4124138653278351], [-0.4027867019176483, -0.40270018577575684]), ([-0.4151156544685364, -0.41513341665267944, -0.4151802957057953, -0.41509974002838135, -0.41509175300598145, -0.4152959883213043, -0.41534921526908875, -0.41533419489860535, -0.41535788774490356, -0.4154604971408844, -0.4154588282108307], [-0.39624133706092834, -0.39659228920936584]), ([-0.06128770858049393, -0.06136852875351906, -0.0613924004137516, -0.061395928263664246, -0.061497703194618225, -0.06150294467806816, -0.06150304526090622], [-0.28310054540634155, -0.2841413915157318]), ([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], [nan, nan])]\n"
          ]
        }
      ],
      "source": [
        "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
        "def defaul():\n",
        "    return defaultdict(list)\n",
        "\n",
        "\n",
        "def BAPG_torch(A, B, a=None, b=None, X=None, epoch=200, eps=1e-5, rho=1e-1):\n",
        "    if a is None:\n",
        "        #a = torch.ones([A.shape[0], 1], dtype=A.dtype).cuda()/A.shape[0]\n",
        "        a = torch.ones([A.shape[0], 1], dtype=A.dtype)/A.shape[0]\n",
        "    if b is None:\n",
        "        #b = torch.ones([B.shape[0], 1], dtype=A.dtype).cuda()/B.shape[0]\n",
        "        b = torch.ones([B.shape[0], 1], dtype=A.dtype)/B.shape[0]\n",
        "    if X is None:\n",
        "        X = a@b.T\n",
        "    obj_list, obj1_list, obj2_list, gap_list = [], [], [], []\n",
        "    for ii in range(epoch):\n",
        "        X = X + 1e-10\n",
        "        X = torch.exp(A@X@B/rho)*X\n",
        "        pi = X * (a / (X @ torch.ones_like(b)))\n",
        "        X = torch.exp(A@pi@B/rho)*pi\n",
        "        X = X * (b.T / (X.T @ torch.ones_like(a)).T)\n",
        "        if (ii+1) % 50 == 0:\n",
        "            objective = -torch.trace(A @ X @ B @ X.T).item()\n",
        "            X2 = (X+pi)/2\n",
        "            gap = (X2.sum(0)-b.squeeze(-1)).norm() + (X2.sum(1)-a.squeeze(-1)).norm()\n",
        "            gap_list.append(gap.item())\n",
        "            if len(obj_list) > 0 and np.abs((objective-obj_list[-1])/obj_list[-1]) < eps:\n",
        "                print('iter:{}, smaller than eps'.format(ii))\n",
        "                obj_list.append(objective)\n",
        "                break\n",
        "            obj_list.append(objective)\n",
        "    return X2, obj_list, gap_list\n",
        "\n",
        "\n",
        "def BAPG_numpy(A, B, a=None, b=None, X=None, epoch=200, eps=1e-5, rho=1e-1):\n",
        "    if a is None:\n",
        "        a = np.ones([A.shape[0], 1], dtype=A.dtype)/A.shape[0]\n",
        "    if b is None:\n",
        "        b = np.ones([B.shape[0], 1], dtype=A.dtype)/B.shape[0]\n",
        "    if X is None:\n",
        "        X = a@b.T\n",
        "    obj_list, gap_list = [], []\n",
        "    for ii in range(epoch):\n",
        "        X = X+1e-10\n",
        "        X = np.exp(A@X@B/rho)*X\n",
        "        pi = X * (a / (X @ np.ones_like(b)))\n",
        "        X = np.exp(A@pi@B/rho)*pi\n",
        "        X = X * (b.T / (X.T @ np.ones_like(a)).T)\n",
        "        if (ii+1) % 50 == 0:\n",
        "            X2 = (X+pi)/2\n",
        "            gap = np.linalg.norm((X2.sum(0)-b.squeeze(-1))) + np.linalg.norm(X2.sum(1)-a.squeeze(-1))\n",
        "            gap_list.append(gap.item())\n",
        "            objective = -np.trace(A @ X @ B @ X.T)\n",
        "            if len(obj_list) > 0 and np.abs((objective-obj_list[-1])/obj_list[-1]) < eps:\n",
        "                print('iter:{}, smaller than eps'.format(ii))\n",
        "                break\n",
        "            obj_list.append(objective)\n",
        "    return X2, obj_list, gap_list\n",
        "seed = 123\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "database = \"synthetic\"\n",
        "rho_list = [0.9, 0.5, 0.2, 0.1, 0.05, 0.01, 0.001]\n",
        "\n",
        "# parser = argparse.ArgumentParser()\n",
        "# parser.add_argument('--dataset', type=str, default='proteins', help='proteins / reddit / enzymes / synthetic')\n",
        "# parser.add_argument('--noise_level', type=float, default=0.)\n",
        "# parser.add_argument('--use_gpu', type=bool, default=False)\n",
        "# parser.add_argument('--loss_fun', type=str, default='square_loss', help='square_loss/kl_loss')\n",
        "# parser.add_argument('--rho', type=float, default=[0.5, 0.2, 0.1, 0.05, 0.01], nargs='+')\n",
        "\n",
        "# args = parser.parse_args()\n",
        "# rho_list = [0.5, 0.2, 0.1, 0.05, 0.01]\n",
        "# database = \"synthetic\"\n",
        "# noise_level = args.noise_level\n",
        "\n",
        "# if database == 'proteins':\n",
        "#     print('------------------Node Matching on PROTIENS---------------')\n",
        "#     with open('data/PROTEINS/matching.pk', 'rb') as f:\n",
        "#         graphs, _ = pickle.load(f)\n",
        "\n",
        "# if database == 'reddit':\n",
        "#     print('------------------Node Matching on REDDIT---------------')\n",
        "#     with open('data/REDDIT-BINARY/matching.pk', 'rb') as f:\n",
        "#         graphs = pickle.load(f)[:500]\n",
        "\n",
        "# if database == 'enzymes':\n",
        "#     print('------------------Node Matching on ENZYMES---------------')\n",
        "#     with open('data/ENZYMES/matching.pk', 'rb') as f:\n",
        "#         graphs = pickle.load(f)\n",
        "\n",
        "\n",
        "#ppppppppppppppppp\n",
        "\n",
        "# if database == 'synthetic':\n",
        "#     graphs, noise_graphs = [], []\n",
        "#     print('------------------Node Matching on Synthetic Database---------------')\n",
        "#     with open('graph1.pk', 'rb') as f:\n",
        "#         graph_pairs = pickle.load(f)\n",
        "#         print(graph_pairs)\n",
        "#         for num_node in [100]:\n",
        "#             for noise_level in [0.1]:\n",
        "#                 for G, G_noise in graph_pairs[(num_node, noise_level)]:\n",
        "#                     graphs.append(G)\n",
        "#                     noise_graphs.append(G_noise)\n",
        "\n",
        "#ppppppppppppppppp\n",
        "\n",
        "# if database != 'synthetic':\n",
        "#     if noise_level > 0:\n",
        "#         noise_graphs = []\n",
        "#         for G_src in graphs:\n",
        "#             G_dst = add_noisy_edges(G_src, noise_level)\n",
        "#             G_dst = add_noisy_nodes(G_dst, noise_level)\n",
        "#             noise_graphs.append(G_dst)\n",
        "#     else:\n",
        "#         noise_graphs = graphs\n",
        "\n",
        "#################\n",
        "\n",
        "\n",
        "# graphs = [ellipse_graph]\n",
        "# noise_graphs = [rotated_ellipse_graph]\n",
        "\n",
        "graphs = [G_german]\n",
        "\n",
        "noise_graphs = [G_russian]\n",
        "\n",
        "noise_level = 0.\n",
        "#################\n",
        "\n",
        "\n",
        "gap_rho = defaultdict(list)\n",
        "acc_rho = defaultdict(list)\n",
        "time_rho = defaultdict(list)\n",
        "gap2_rho = defaultdict(list)\n",
        "acc2_rho = defaultdict(list)\n",
        "time2_rho = defaultdict(list)\n",
        "obj_lists = []\n",
        "for j in range(len(graphs)):\n",
        "    print(j)\n",
        "    G = graphs[j]\n",
        "    G_noise = noise_graphs[j]\n",
        "    G_adj = nx.to_numpy_array(G).astype(np.float32)\n",
        "    G_adj_noise = nx.to_numpy_array(G_noise).astype(np.float32)\n",
        "    #G_adj_gpu = torch.tensor(G_adj).cuda()\n",
        "    G_adj_gpu = torch.tensor(G_adj)\n",
        "    #G_adj_noise_gpu = torch.tensor(G_adj_noise).cuda()\n",
        "    G_adj_noise_gpu = torch.tensor(G_adj_noise)\n",
        "    m, n = G_adj.shape[0], G_adj_noise.shape[0]\n",
        "    for rho in rho_list:  #0.5,0.2,0.1,0.05,\n",
        "        epoch = 2000 if rho < 0.2 else 4000\n",
        "        start = time.time()\n",
        "        # coup_bap, obj_list, gap_list = BAPG_numpy(\n",
        "        #     A=G_adj, B=G_adj_noise, epoch=2000, rho=rho, eps=1e-5, scaling=1.01, max_rho=0.5)\n",
        "        if True:\n",
        "            coup_bap, obj_list1, gap_list = BAPG_torch(\n",
        "                A=G_adj_gpu, B=G_adj_noise_gpu, epoch=epoch, rho=rho, eps=1e-5)\n",
        "            end = time.time()\n",
        "            acc = node_correctness(coup_bap.cpu().numpy(), np.eye(m))\n",
        "            print(rho, gap_list[-1], acc)\n",
        "            acc_rho[rho].append(acc)\n",
        "            time_rho[rho].append(end-start)\n",
        "            gap_rho[rho].append(gap_list[-1])\n",
        "            coup_bap, obj_list2, gap_list = BAPG_torch(\n",
        "                A=G_adj_gpu, B=G_adj_noise_gpu, X=coup_bap, epoch=100, rho=100, eps=1e-5)\n",
        "            end = time.time()\n",
        "            obj_lists.append((obj_list1, obj_list2))\n",
        "            acc = node_correctness(coup_bap.cpu().numpy(), np.eye(m))\n",
        "            print('100', gap_list[-1], acc)\n",
        "        else:\n",
        "            coup_bap, obj_list1, gap_list = BAPG_numpy(\n",
        "                A=G_adj, B=G_adj_noise, epoch=2000, rho=rho, eps=1e-5)\n",
        "            end = time.time()\n",
        "            print(\"fffff\")\n",
        "            print(obj_list1)\n",
        "            print(\"fffff\")\n",
        "            acc = node_correctness(coup_bap, np.eye(m))\n",
        "            print(rho, gap_list[-1], acc)\n",
        "            acc_rho[rho].append(acc)\n",
        "            time_rho[rho].append(end-start)\n",
        "            gap_rho[rho].append(gap_list[-1])\n",
        "            coup_bap, obj_list2, gap_list = BAPG_numpy(\n",
        "                A=G_adj, B=G_adj_noise, X=coup_bap, epoch=100, rho=100, eps=1e-5)\n",
        "            end = time.time()\n",
        "            obj_lists.append((obj_list1, obj_list2))\n",
        "            acc = node_correctness(coup_bap, np.eye(m))\n",
        "            print('100', gap_list[-1], acc)\n",
        "\n",
        "        acc2_rho[rho].append(acc)\n",
        "        time2_rho[rho].append(end-start)\n",
        "        gap2_rho[rho].append(gap_list[-1])\n",
        "\n",
        "\n",
        "for rho in rho_list:\n",
        "    print('rho:{},gap:{:.2e},acc:{:.5f},time:{:.1f},gap2:{:.2e},acc2:{:.5f},time2:{:.1f}'.format(\n",
        "        rho, np.mean(gap_rho[rho]), np.mean(acc_rho[rho])*100, np.sum(time_rho[rho]),\n",
        "        np.mean(gap2_rho[rho]), np.mean(acc2_rho[rho])*100, np.sum(time2_rho[rho])))\n",
        "\n",
        "    with open('result.txt', 'a+') as f:\n",
        "        f.write('Data:{},Noise:{},rho:{},gap:{:.2e},acc:{:.5f},time:{:.1f},gap2:{:.2e},acc2:{:.5f},time2:{:.1f}\\n'.format(\n",
        "            database, noise_level, rho, np.mean(gap_rho[rho]), np.mean(acc_rho[rho])*100, np.sum(time_rho[rho]),\n",
        "            np.mean(gap2_rho[rho]), np.mean(acc2_rho[rho])*100, np.sum(time2_rho[rho])))\n",
        "print('-'*10)\n",
        "print(type(G), type(G_noise), sep=\"    \")\n",
        "print('-'*3)\n",
        "print(type(G_adj), type(G_adj_noise), sep=\"    \")\n",
        "print('-'*10)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# nx.draw_networkx(G, with_labels=True, node_size=10, pos=nx.spring_layout(G), font_size=8, width=0.1)\n",
        "# plt.savefig(\"G.png\")\n",
        "# nx.draw_networkx(G_noise, with_labels=True, node_size=10, font_size=8, width=0.1)\n",
        "# plt.savefig(\"G_noise.png\")\n",
        "\n",
        "\n",
        "\n",
        "print('-'*10)\n",
        "print(obj_lists)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}